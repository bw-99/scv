2025-05-09 00:43:34,122 P708022 INFO FuxiCTR version: 2.3.3
2025-05-09 00:43:34,123 P708022 INFO Params: {
    "batch_size": "10000",
    "data_format": "csv",
    "data_root": "dataset/",
    "dataset_id": "KKBox_x1",
    "debug_mode": "False",
    "early_stop_patience": "2",
    "embedding_dim": "128",
    "embedding_regularizer": "0.0005",
    "epochs": "100",
    "eval_steps": "None",
    "experiment_id": "EulerNet_KKBox_x1",
    "feature_cols": "[{'active': True, 'dtype': 'str', 'name': ['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', 'city', 'gender', 'registered_via', 'language'], 'type': 'categorical'}, {'active': True, 'dtype': 'str', 'encoder': 'MaskedSumPooling', 'max_len': 3, 'name': 'genre_ids', 'type': 'sequence'}, {'active': True, 'dtype': 'str', 'encoder': 'MaskedSumPooling', 'max_len': 3, 'name': 'artist_name', 'type': 'sequence'}, {'active': True, 'dtype': 'str', 'name': 'isrc', 'preprocess': 'extract_country_code', 'type': 'categorical'}, {'active': True, 'dtype': 'str', 'name': 'bd', 'preprocess': 'bucketize_age', 'type': 'categorical'}]",
    "feature_config": "None",
    "feature_specs": "None",
    "gpu": "1",
    "group_id": "None",
    "label_col": "{'dtype': 'float', 'name': 'label'}",
    "layer_norm": "True",
    "learning_rate": "0.001",
    "loss": "binary_crossentropy",
    "mask_rate": "0",
    "metrics": "['logloss', 'AUC']",
    "min_categr_count": "10",
    "model": "EulerNet",
    "model_id": "EulerNet_KKBox_x1",
    "model_root": "./checkpoints/",
    "monitor": "{'AUC': 1, 'logloss': 0}",
    "monitor_mode": "max",
    "net_ex_dropout": "0.2",
    "net_im_dropout": "0",
    "num_workers": "16",
    "optimizer": "adam",
    "pickle_feature_encoder": "True",
    "save_best_only": "True",
    "save_feature_interaction": "0",
    "seed": "2024",
    "shape": "[10, 10]",
    "task": "binary_classification",
    "test_data": "dataset/KKBox_x1/test.csv",
    "train_data": "dataset/KKBox_x1/train.csv",
    "use_features": "None",
    "valid_data": "dataset/KKBox_x1/valid.csv",
    "verbose": "1"
}
2025-05-09 00:43:34,123 P708022 INFO Set up feature processor...
2025-05-09 00:43:34,123 P708022 WARNING Skip rebuilding dataset/KKBox_x1/feature_map.json. Please delete it manually if rebuilding is required.
2025-05-09 00:43:34,123 P708022 INFO Load feature_map from json: dataset/KKBox_x1/feature_map.json
2025-05-09 00:43:34,123 P708022 INFO Set column index...
2025-05-09 00:43:34,123 P708022 INFO Feature specs: {
    "artist_name": "{'source': '', 'type': 'sequence', 'feature_encoder': 'layers.MaskedAveragePooling()', 'padding_idx': 0, 'max_len': 3, 'vocab_size': 11976}",
    "bd": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 9}",
    "city": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 23}",
    "gender": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 4}",
    "genre_ids": "{'source': '', 'type': 'sequence', 'feature_encoder': 'layers.MaskedAveragePooling()', 'padding_idx': 0, 'max_len': 3, 'vocab_size': 346}",
    "isrc": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 80}",
    "language": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 12}",
    "msno": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 25963}",
    "registered_via": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 7}",
    "song_id": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 53291}",
    "source_screen_name": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 21}",
    "source_system_tab": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 10}",
    "source_type": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 14}"
}
/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/fuxictr/pytorch/models/rank_model.py:65: UserWarning: mods argument is not needed anymore, you can stop passing it
  self.flop_counter = FlopCounterMode(mods=self, display=False, depth=None)
2025-05-09 00:43:35,153 P708022 INFO Total number of parameters: 3778548.
2025-05-09 00:43:35,153 P708022 INFO Total number of parameters: 15523316.
2025-05-09 00:43:35,153 P708022 INFO Loading datasets...
2025-05-09 00:43:52,105 P708022 INFO Train samples: total/5901932, blocks/1
2025-05-09 00:43:54,884 P708022 INFO Validation samples: total/737743, blocks/1
2025-05-09 00:43:54,884 P708022 INFO Loading train and validation data done.
2025-05-09 00:43:54,884 P708022 INFO Start training: 591 batches/epoch
2025-05-09 00:43:54,884 P708022 INFO ************ Epoch=1 start ************
remove_modelremove_modelremove_modelremove_modelremove_modelremove_modelremove_modelremove_modelremove_modelremove_model True
**************
./config/ EulerNet_KKBox_x1
**************
EulerNet_KKBox_x1
*******************
dataset/KKBox_x1
fucking {'active': True, 'dtype': 'str', 'name': ['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', 'city', 'gender', 'registered_via', 'language'], 'type': 'categorical'}
fucking {'active': True, 'dtype': 'str', 'encoder': 'MaskedSumPooling', 'max_len': 3, 'name': 'genre_ids', 'type': 'sequence'}
fucking {'active': True, 'dtype': 'str', 'encoder': 'MaskedSumPooling', 'max_len': 3, 'name': 'artist_name', 'type': 'sequence'}
fucking {'active': True, 'dtype': 'str', 'name': 'isrc', 'preprocess': 'extract_country_code', 'type': 'categorical'}
fucking {'active': True, 'dtype': 'str', 'name': 'bd', 'preprocess': 'bucketize_age', 'type': 'categorical'}
mask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is none
mask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is none
without emb dim
  0%|          | 0/591 [00:00<?, ?it/s]  0%|          | 1/591 [00:01<17:29,  1.78s/it]  1%|          | 4/591 [00:01<03:39,  2.67it/s]  1%|          | 6/591 [00:02<02:16,  4.29it/s]  2%|â–         | 9/591 [00:02<01:23,  6.98it/s]  2%|â–         | 12/591 [00:02<01:03,  9.08it/s]  3%|â–Ž         | 15/591 [00:02<00:50, 11.42it/s]  3%|â–Ž         | 18/591 [00:02<00:41, 13.67it/s]  4%|â–Ž         | 21/591 [00:02<00:36, 15.66it/s]  4%|â–         | 24/591 [00:02<00:32, 17.36it/s]  5%|â–         | 27/591 [00:03<00:30, 18.74it/s]  5%|â–Œ         | 30/591 [00:03<00:28, 19.82it/s]  6%|â–Œ         | 33/591 [00:03<00:27, 20.55it/s]  6%|â–Œ         | 36/591 [00:03<00:26, 20.68it/s]  7%|â–‹         | 39/591 [00:03<00:26, 20.95it/s]  7%|â–‹         | 42/591 [00:03<00:26, 21.10it/s]  8%|â–Š         | 45/591 [00:03<00:25, 21.39it/s]  8%|â–Š         | 48/591 [00:03<00:25, 21.47it/s]  9%|â–Š         | 51/591 [00:04<00:25, 21.13it/s]  9%|â–‰         | 54/591 [00:04<00:25, 21.02it/s] 10%|â–‰         | 57/591 [00:04<00:25, 20.82it/s] 10%|â–ˆ         | 60/591 [00:04<00:25, 20.84it/s] 11%|â–ˆ         | 63/591 [00:04<00:25, 20.67it/s] 11%|â–ˆ         | 66/591 [00:04<00:25, 20.85it/s] 12%|â–ˆâ–        | 69/591 [00:05<00:24, 20.89it/s] 12%|â–ˆâ–        | 72/591 [00:05<00:25, 20.54it/s] 13%|â–ˆâ–Ž        | 75/591 [00:05<00:24, 20.88it/s] 13%|â–ˆâ–Ž        | 78/591 [00:05<00:24, 20.97it/s] 14%|â–ˆâ–Ž        | 81/591 [00:05<00:24, 21.07it/s] 14%|â–ˆâ–        | 84/591 [00:05<00:23, 21.28it/s] 15%|â–ˆâ–        | 87/591 [00:05<00:23, 21.19it/s] 15%|â–ˆâ–Œ        | 90/591 [00:05<00:23, 21.27it/s] 16%|â–ˆâ–Œ        | 93/591 [00:06<00:23, 21.27it/s] 16%|â–ˆâ–Œ        | 96/591 [00:06<00:23, 21.18it/s] 17%|â–ˆâ–‹        | 99/591 [00:06<00:23, 21.13it/s] 17%|â–ˆâ–‹        | 102/591 [00:06<00:23, 21.13it/s] 18%|â–ˆâ–Š        | 105/591 [00:06<00:23, 21.03it/s] 18%|â–ˆâ–Š        | 108/591 [00:06<00:22, 21.23it/s] 19%|â–ˆâ–‰        | 111/591 [00:06<00:22, 21.24it/s] 19%|â–ˆâ–‰        | 114/591 [00:07<00:22, 21.11it/s] 20%|â–ˆâ–‰        | 117/591 [00:07<00:22, 21.06it/s] 20%|â–ˆâ–ˆ        | 120/591 [00:07<00:22, 21.08it/s] 21%|â–ˆâ–ˆ        | 123/591 [00:07<00:22, 21.23it/s] 21%|â–ˆâ–ˆâ–       | 126/591 [00:07<00:21, 21.35it/s] 22%|â–ˆâ–ˆâ–       | 129/591 [00:07<00:21, 21.38it/s] 22%|â–ˆâ–ˆâ–       | 132/591 [00:07<00:21, 21.33it/s] 23%|â–ˆâ–ˆâ–Ž       | 135/591 [00:08<00:21, 21.38it/s] 23%|â–ˆâ–ˆâ–Ž       | 138/591 [00:08<00:21, 21.34it/s] 24%|â–ˆâ–ˆâ–       | 141/591 [00:08<00:21, 21.34it/s] 24%|â–ˆâ–ˆâ–       | 144/591 [00:08<00:21, 21.22it/s] 25%|â–ˆâ–ˆâ–       | 147/591 [00:08<00:20, 21.37it/s] 25%|â–ˆâ–ˆâ–Œ       | 150/591 [00:08<00:20, 21.35it/s] 26%|â–ˆâ–ˆâ–Œ       | 153/591 [00:08<00:20, 21.39it/s] 26%|â–ˆâ–ˆâ–‹       | 156/591 [00:09<00:20, 21.44it/s] 27%|â–ˆâ–ˆâ–‹       | 159/591 [00:09<00:20, 21.47it/s] 27%|â–ˆâ–ˆâ–‹       | 162/591 [00:09<00:20, 21.40it/s] 28%|â–ˆâ–ˆâ–Š       | 165/591 [00:09<00:19, 21.42it/s] 28%|â–ˆâ–ˆâ–Š       | 168/591 [00:09<00:20, 21.03it/s] 29%|â–ˆâ–ˆâ–‰       | 171/591 [00:09<00:19, 21.04it/s] 29%|â–ˆâ–ˆâ–‰       | 174/591 [00:09<00:19, 21.17it/s] 30%|â–ˆâ–ˆâ–‰       | 177/591 [00:10<00:19, 21.20it/s] 30%|â–ˆâ–ˆâ–ˆ       | 180/591 [00:10<00:19, 21.27it/s] 31%|â–ˆâ–ˆâ–ˆ       | 183/591 [00:10<00:19, 21.15it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 186/591 [00:10<00:19, 21.12it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 189/591 [00:10<00:19, 20.89it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 192/591 [00:10<00:18, 21.17it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 195/591 [00:10<00:18, 21.32it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 198/591 [00:11<00:18, 21.07it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 201/591 [00:11<00:18, 21.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 204/591 [00:11<00:18, 21.25it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 207/591 [00:11<00:18, 21.32it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 210/591 [00:11<00:17, 21.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 213/591 [00:11<00:17, 21.33it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 216/591 [00:11<00:17, 21.27it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 219/591 [00:12<00:17, 21.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 222/591 [00:12<00:17, 21.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 225/591 [00:12<00:17, 21.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 228/591 [00:12<00:17, 20.92it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 231/591 [00:12<00:17, 21.03it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 234/591 [00:12<00:17, 20.99it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 237/591 [00:12<00:16, 20.90it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 240/591 [00:13<00:16, 20.80it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 243/591 [00:13<00:16, 21.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 246/591 [00:13<00:16, 21.16it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 249/591 [00:13<00:16, 21.16it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 252/591 [00:13<00:15, 21.32it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 255/591 [00:13<00:15, 21.50it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 258/591 [00:13<00:15, 21.58it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 261/591 [00:14<00:15, 21.72it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 264/591 [00:14<00:15, 21.77it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 267/591 [00:14<00:14, 21.67it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 270/591 [00:14<00:14, 21.78it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 273/591 [00:14<00:14, 21.78it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 276/591 [00:14<00:14, 21.93it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 279/591 [00:14<00:14, 21.36it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 282/591 [00:15<00:14, 21.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 285/591 [00:15<00:14, 21.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 288/591 [00:15<00:14, 21.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 291/591 [00:15<00:14, 21.41it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 294/591 [00:15<00:13, 21.39it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 297/591 [00:15<00:13, 21.09it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 300/591 [00:15<00:13, 21.20it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 303/591 [00:16<00:13, 21.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 306/591 [00:16<00:13, 21.21it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 309/591 [00:16<00:13, 21.45it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 312/591 [00:16<00:12, 21.49it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 315/591 [00:16<00:12, 21.42it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 318/591 [00:16<00:12, 21.43it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 321/591 [00:16<00:12, 21.40it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 324/591 [00:16<00:12, 21.46it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 327/591 [00:17<00:12, 21.43it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 330/591 [00:17<00:12, 21.46it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 333/591 [00:17<00:12, 20.43it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 336/591 [00:17<00:12, 20.48it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 339/591 [00:17<00:12, 20.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 342/591 [00:17<00:12, 20.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 345/591 [00:18<00:12, 19.86it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 348/591 [00:18<00:12, 20.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 351/591 [00:18<00:11, 20.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 354/591 [00:18<00:11, 20.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 357/591 [00:18<00:11, 20.27it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 360/591 [00:18<00:11, 20.31it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 363/591 [00:18<00:11, 20.20it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 366/591 [00:19<00:11, 20.10it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 369/591 [00:19<00:11, 19.68it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 371/591 [00:19<00:11, 18.45it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 374/591 [00:19<00:11, 19.33it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 377/591 [00:19<00:10, 19.46it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 380/591 [00:19<00:10, 19.96it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 383/591 [00:19<00:10, 20.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 386/591 [00:20<00:10, 20.13it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 389/591 [00:20<00:10, 20.16it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 392/591 [00:20<00:09, 20.30it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 395/591 [00:20<00:09, 20.62it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 398/591 [00:20<00:09, 20.78it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 401/591 [00:20<00:09, 20.92it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 404/591 [00:20<00:08, 20.97it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 407/591 [00:21<00:08, 20.78it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 410/591 [00:21<00:08, 20.98it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 413/591 [00:21<00:08, 20.99it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 416/591 [00:21<00:08, 21.00it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 419/591 [00:21<00:08, 20.68it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 422/591 [00:21<00:08, 20.26it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 425/591 [00:21<00:08, 19.79it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 427/591 [00:22<00:08, 19.39it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 429/591 [00:22<00:09, 16.90it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 431/591 [00:22<00:09, 16.27it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 433/591 [00:22<00:11, 14.33it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 435/591 [00:22<00:10, 14.29it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 437/591 [00:22<00:11, 13.83it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 439/591 [00:23<00:10, 13.89it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 441/591 [00:23<00:10, 13.90it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 443/591 [00:23<00:10, 13.88it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 446/591 [00:23<00:09, 14.62it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 448/591 [00:23<00:09, 15.25it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 450/591 [00:23<00:10, 13.82it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 452/591 [00:23<00:10, 13.26it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 454/591 [00:24<00:11, 12.25it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 456/591 [00:24<00:10, 13.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 458/591 [00:24<00:09, 14.71it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 460/591 [00:24<00:09, 14.29it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 463/591 [00:24<00:07, 16.38it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 465/591 [00:24<00:08, 14.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 467/591 [00:24<00:08, 14.63it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 469/591 [00:25<00:07, 15.38it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 471/591 [00:25<00:07, 15.32it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 473/591 [00:25<00:08, 14.74it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 475/591 [00:25<00:07, 15.25it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 477/591 [00:25<00:06, 16.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 479/591 [00:25<00:07, 15.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 481/591 [00:26<00:09, 11.52it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 483/591 [00:26<00:08, 12.26it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 485/591 [00:26<00:07, 13.42it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 487/591 [00:26<00:08, 12.25it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 489/591 [00:26<00:07, 13.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 492/591 [00:26<00:06, 15.21it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 494/591 [00:26<00:06, 15.92it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 497/591 [00:27<00:05, 16.75it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 499/591 [00:27<00:05, 17.45it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 502/591 [00:27<00:04, 18.61it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 505/591 [00:27<00:04, 19.25it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 508/591 [00:27<00:04, 19.72it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 510/591 [00:27<00:04, 19.67it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 513/591 [00:27<00:03, 20.21it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 516/591 [00:27<00:03, 20.51it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 519/591 [00:28<00:03, 20.58it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 522/591 [00:28<00:03, 20.26it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 525/591 [00:28<00:03, 20.65it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 528/591 [00:28<00:03, 20.20it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 531/591 [00:28<00:02, 20.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 534/591 [00:28<00:02, 20.36it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 537/591 [00:28<00:02, 20.38it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 540/591 [00:29<00:02, 20.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 543/591 [00:29<00:02, 20.36it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 546/591 [00:29<00:02, 20.28it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 549/591 [00:29<00:02, 20.48it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 552/591 [00:29<00:01, 19.52it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 555/591 [00:29<00:01, 19.89it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 558/591 [00:30<00:01, 20.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 561/591 [00:30<00:03,  8.44it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 564/591 [00:31<00:02, 10.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 567/591 [00:31<00:01, 12.21it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 570/591 [00:31<00:01, 14.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 573/591 [00:31<00:01, 15.55it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 576/591 [00:31<00:00, 17.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 579/591 [00:31<00:00, 18.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 582/591 [00:31<00:00, 19.35it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 585/591 [00:31<00:00, 19.86it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 588/591 [00:32<00:00, 20.23it/s]2025-05-09 00:44:27,121 P708022 INFO Train loss: 49.567756
2025-05-09 00:44:27,122 P708022 INFO Evaluation @epoch 1 - batch 591: 

  0%|          | 0/74 [00:00<?, ?it/s][A
  1%|â–         | 1/74 [00:00<01:03,  1.15it/s][A
  7%|â–‹         | 5/74 [00:00<00:10,  6.63it/s][A
 15%|â–ˆâ–        | 11/74 [00:01<00:04, 15.32it/s][A
 22%|â–ˆâ–ˆâ–       | 16/74 [00:01<00:02, 21.82it/s][A
 30%|â–ˆâ–ˆâ–‰       | 22/74 [00:01<00:01, 29.57it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/74 [00:01<00:01, 35.95it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34/74 [00:01<00:00, 41.49it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40/74 [00:01<00:00, 45.28it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/74 [00:01<00:00, 48.92it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53/74 [00:01<00:00, 53.09it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60/74 [00:01<00:00, 55.56it/s][A
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67/74 [00:02<00:00, 57.27it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 59.41it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 33.08it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:44:30,026 P708022 INFO [Metrics] AUC: 0.500000 - logloss: 8.002364
2025-05-09 00:44:30,033 P708022 INFO Save best model: monitor(max)=0.500000

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 591/591 [00:35<00:00,  2.88it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 591/591 [00:35<00:00, 16.73it/s]2025-05-09 00:44:30,214 P708022 INFO ************ Epoch=1 end ************

  0%|          | 0/591 [00:00<?, ?it/s]  0%|          | 1/591 [00:01<12:32,  1.28s/it]  0%|          | 2/591 [00:01<05:44,  1.71it/s]  1%|          | 5/591 [00:01<01:56,  5.03it/s]  1%|          | 7/591 [00:01<01:21,  7.18it/s]  2%|â–         | 10/591 [00:01<00:55, 10.45it/s]  2%|â–         | 13/591 [00:01<00:43, 13.18it/s]  3%|â–Ž         | 16/591 [00:02<00:37, 15.37it/s]  3%|â–Ž         | 19/591 [00:02<00:33, 16.84it/s]  4%|â–Ž         | 22/591 [00:02<00:31, 18.17it/s]  4%|â–         | 25/591 [00:02<00:29, 19.12it/s]  5%|â–         | 28/591 [00:02<00:28, 19.81it/s]  5%|â–Œ         | 31/591 [00:02<00:27, 20.32it/s]  6%|â–Œ         | 34/591 [00:02<00:27, 20.58it/s]  6%|â–‹         | 37/591 [00:03<00:26, 20.58it/s]  7%|â–‹         | 40/591 [00:03<00:26, 20.70it/s]  7%|â–‹         | 43/591 [00:03<00:26, 20.46it/s]  8%|â–Š         | 46/591 [00:03<00:26, 20.60it/s]  8%|â–Š         | 49/591 [00:03<00:26, 20.56it/s]  9%|â–‰         | 52/591 [00:03<00:25, 20.87it/s]  9%|â–‰         | 55/591 [00:03<00:25, 20.95it/s] 10%|â–‰         | 58/591 [00:04<00:25, 21.00it/s] 10%|â–ˆ         | 61/591 [00:04<00:25, 20.80it/s] 11%|â–ˆ         | 64/591 [00:04<00:25, 20.82it/s] 11%|â–ˆâ–        | 67/591 [00:04<00:25, 20.41it/s] 12%|â–ˆâ–        | 70/591 [00:04<00:25, 20.75it/s] 12%|â–ˆâ–        | 73/591 [00:04<00:25, 20.64it/s] 13%|â–ˆâ–Ž        | 76/591 [00:04<00:24, 20.69it/s] 13%|â–ˆâ–Ž        | 79/591 [00:05<00:24, 20.76it/s] 14%|â–ˆâ–        | 82/591 [00:05<00:24, 20.92it/s] 14%|â–ˆâ–        | 85/591 [00:05<00:24, 20.96it/s] 15%|â–ˆâ–        | 88/591 [00:05<00:24, 20.27it/s] 15%|â–ˆâ–Œ        | 91/591 [00:05<00:24, 20.33it/s] 16%|â–ˆâ–Œ        | 94/591 [00:05<00:24, 20.10it/s] 16%|â–ˆâ–‹        | 97/591 [00:05<00:24, 20.12it/s] 17%|â–ˆâ–‹        | 100/591 [00:06<00:23, 20.47it/s] 17%|â–ˆâ–‹        | 103/591 [00:06<00:23, 20.62it/s] 18%|â–ˆâ–Š        | 106/591 [00:06<00:23, 20.91it/s] 18%|â–ˆâ–Š        | 109/591 [00:06<00:22, 21.02it/s] 19%|â–ˆâ–‰        | 112/591 [00:06<00:22, 21.20it/s] 19%|â–ˆâ–‰        | 115/591 [00:06<00:22, 21.28it/s] 20%|â–ˆâ–‰        | 118/591 [00:06<00:22, 21.17it/s] 20%|â–ˆâ–ˆ        | 121/591 [00:07<00:22, 21.31it/s] 21%|â–ˆâ–ˆ        | 124/591 [00:07<00:22, 20.51it/s] 21%|â–ˆâ–ˆâ–       | 127/591 [00:07<00:22, 20.66it/s] 22%|â–ˆâ–ˆâ–       | 130/591 [00:07<00:23, 19.77it/s] 22%|â–ˆâ–ˆâ–       | 132/591 [00:07<00:23, 19.20it/s] 23%|â–ˆâ–ˆâ–Ž       | 135/591 [00:07<00:23, 19.33it/s] 23%|â–ˆâ–ˆâ–Ž       | 137/591 [00:07<00:24, 18.26it/s] 24%|â–ˆâ–ˆâ–Ž       | 139/591 [00:08<00:24, 18.14it/s] 24%|â–ˆâ–ˆâ–       | 141/591 [00:08<00:25, 17.78it/s] 24%|â–ˆâ–ˆâ–       | 144/591 [00:08<00:23, 18.64it/s] 25%|â–ˆâ–ˆâ–       | 146/591 [00:08<00:24, 18.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 149/591 [00:08<00:23, 18.71it/s] 26%|â–ˆâ–ˆâ–Œ       | 151/591 [00:08<00:24, 17.97it/s] 26%|â–ˆâ–ˆâ–Œ       | 154/591 [00:08<00:23, 18.96it/s] 27%|â–ˆâ–ˆâ–‹       | 157/591 [00:08<00:22, 19.31it/s] 27%|â–ˆâ–ˆâ–‹       | 160/591 [00:09<00:21, 19.94it/s] 28%|â–ˆâ–ˆâ–Š       | 163/591 [00:09<00:21, 20.24it/s] 28%|â–ˆâ–ˆâ–Š       | 166/591 [00:09<00:20, 20.71it/s] 29%|â–ˆâ–ˆâ–Š       | 169/591 [00:09<00:20, 20.16it/s] 29%|â–ˆâ–ˆâ–‰       | 172/591 [00:09<00:20, 20.55it/s] 30%|â–ˆâ–ˆâ–‰       | 175/591 [00:09<00:20, 20.72it/s] 30%|â–ˆâ–ˆâ–ˆ       | 178/591 [00:09<00:19, 20.95it/s] 31%|â–ˆâ–ˆâ–ˆ       | 181/591 [00:10<00:19, 20.65it/s] 31%|â–ˆâ–ˆâ–ˆ       | 184/591 [00:10<00:19, 20.83it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 187/591 [00:10<00:19, 20.92it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 190/591 [00:10<00:19, 20.55it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 193/591 [00:10<00:19, 20.62it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 196/591 [00:10<00:19, 20.74it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 199/591 [00:11<00:18, 20.90it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 202/591 [00:11<00:18, 20.88it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 205/591 [00:11<00:18, 20.81it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 208/591 [00:11<00:19, 19.88it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 210/591 [00:11<00:19, 19.43it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 212/591 [00:11<00:19, 19.13it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 214/591 [00:11<00:20, 18.25it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 217/591 [00:11<00:19, 19.08it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 219/591 [00:12<00:19, 18.84it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 222/591 [00:12<00:18, 19.53it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 225/591 [00:12<00:18, 19.90it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 227/591 [00:12<00:18, 19.61it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 230/591 [00:12<00:18, 19.79it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 232/591 [00:12<00:18, 19.18it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 235/591 [00:12<00:18, 19.59it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 237/591 [00:12<00:18, 19.60it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 240/591 [00:13<00:17, 20.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 242/591 [00:13<00:17, 20.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 245/591 [00:13<00:16, 20.52it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 248/591 [00:13<00:16, 20.51it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 251/591 [00:13<00:16, 20.73it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 254/591 [00:13<00:16, 20.90it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 257/591 [00:13<00:15, 20.92it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 260/591 [00:14<00:15, 20.90it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 263/591 [00:14<00:15, 21.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 266/591 [00:14<00:15, 21.16it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 269/591 [00:14<00:15, 20.94it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 272/591 [00:14<00:15, 20.98it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 275/591 [00:14<00:15, 20.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 278/591 [00:14<00:15, 20.40it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 281/591 [00:15<00:15, 20.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 284/591 [00:15<00:14, 20.73it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 287/591 [00:15<00:14, 20.82it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 290/591 [00:15<00:14, 20.84it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 293/591 [00:15<00:14, 20.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 296/591 [00:15<00:14, 20.36it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 299/591 [00:15<00:14, 20.32it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 302/591 [00:16<00:14, 20.17it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 305/591 [00:16<00:13, 20.49it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 308/591 [00:16<00:13, 20.29it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 311/591 [00:16<00:13, 20.50it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 314/591 [00:16<00:13, 20.18it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 317/591 [00:16<00:13, 20.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 320/591 [00:16<00:13, 20.36it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 323/591 [00:17<00:13, 20.45it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 326/591 [00:17<00:12, 20.48it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 329/591 [00:17<00:12, 20.41it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 332/591 [00:17<00:12, 20.37it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 335/591 [00:17<00:12, 20.16it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 338/591 [00:17<00:12, 20.46it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 341/591 [00:18<00:12, 20.45it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 344/591 [00:18<00:12, 20.57it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 347/591 [00:18<00:11, 20.42it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 350/591 [00:18<00:11, 20.50it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 353/591 [00:18<00:11, 20.73it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 356/591 [00:18<00:11, 20.87it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 359/591 [00:18<00:11, 21.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 362/591 [00:19<00:10, 21.15it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 365/591 [00:19<00:10, 21.15it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 368/591 [00:19<00:10, 20.91it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 371/591 [00:19<00:10, 20.78it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 374/591 [00:19<00:10, 20.83it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 377/591 [00:19<00:10, 20.70it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 380/591 [00:19<00:10, 20.47it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 383/591 [00:20<00:10, 20.76it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 386/591 [00:20<00:09, 21.15it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 389/591 [00:20<00:09, 20.93it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 392/591 [00:20<00:09, 20.80it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 395/591 [00:20<00:09, 20.60it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 398/591 [00:20<00:09, 20.88it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 401/591 [00:20<00:09, 20.95it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 404/591 [00:21<00:08, 20.85it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 407/591 [00:21<00:08, 20.76it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 410/591 [00:21<00:08, 20.79it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 413/591 [00:21<00:08, 21.05it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 416/591 [00:21<00:08, 20.79it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 419/591 [00:21<00:08, 20.91it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 422/591 [00:21<00:08, 20.76it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 425/591 [00:22<00:07, 20.86it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 428/591 [00:22<00:07, 20.67it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 431/591 [00:22<00:07, 20.54it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 434/591 [00:22<00:07, 20.63it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 437/591 [00:22<00:07, 20.82it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 440/591 [00:22<00:07, 20.94it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 443/591 [00:22<00:07, 20.97it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 446/591 [00:23<00:06, 20.94it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 449/591 [00:23<00:06, 21.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 452/591 [00:23<00:06, 21.15it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 455/591 [00:23<00:06, 21.26it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 458/591 [00:23<00:06, 20.96it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 461/591 [00:23<00:06, 21.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 464/591 [00:23<00:06, 20.67it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 467/591 [00:24<00:05, 20.93it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 470/591 [00:24<00:05, 21.13it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 473/591 [00:24<00:05, 21.26it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 476/591 [00:24<00:05, 21.21it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 479/591 [00:24<00:05, 21.41it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 482/591 [00:24<00:05, 21.28it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 485/591 [00:24<00:05, 21.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 488/591 [00:25<00:05, 20.22it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 491/591 [00:25<00:04, 20.38it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 494/591 [00:25<00:04, 20.48it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 497/591 [00:25<00:04, 20.75it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 500/591 [00:25<00:04, 20.81it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 503/591 [00:25<00:04, 20.75it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 506/591 [00:25<00:04, 20.70it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 509/591 [00:26<00:03, 20.80it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 512/591 [00:26<00:03, 20.72it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 515/591 [00:26<00:03, 20.61it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 518/591 [00:26<00:03, 20.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 521/591 [00:26<00:03, 20.29it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 524/591 [00:26<00:03, 20.32it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 527/591 [00:26<00:03, 20.36it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 530/591 [00:27<00:02, 20.48it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 533/591 [00:27<00:02, 20.61it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 536/591 [00:27<00:02, 20.69it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 539/591 [00:27<00:02, 20.92it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 542/591 [00:27<00:02, 21.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 545/591 [00:27<00:02, 21.10it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 548/591 [00:27<00:02, 21.12it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 551/591 [00:28<00:01, 21.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 554/591 [00:28<00:01, 21.10it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 557/591 [00:28<00:01, 20.51it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 560/591 [00:29<00:03,  9.17it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 563/591 [00:29<00:02, 11.10it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 566/591 [00:29<00:01, 13.10it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 569/591 [00:29<00:01, 14.91it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 572/591 [00:29<00:01, 16.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 575/591 [00:29<00:00, 17.42it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 578/591 [00:29<00:00, 18.54it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 581/591 [00:30<00:00, 19.36it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 584/591 [00:30<00:00, 20.26it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 587/591 [00:30<00:00, 20.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 590/591 [00:30<00:00, 21.22it/s]2025-05-09 00:45:00,759 P708022 INFO Train loss: 49.650407
2025-05-09 00:45:00,759 P708022 INFO Evaluation @epoch 2 - batch 591: 

  0%|          | 0/74 [00:00<?, ?it/s][A
  1%|â–         | 1/74 [00:00<00:55,  1.31it/s][A
  9%|â–‰         | 7/74 [00:00<00:06, 10.33it/s][A
 18%|â–ˆâ–Š        | 13/74 [00:00<00:03, 18.89it/s][A
 26%|â–ˆâ–ˆâ–Œ       | 19/74 [00:01<00:02, 26.36it/s][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 25/74 [00:01<00:01, 33.59it/s][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/74 [00:01<00:01, 39.18it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/74 [00:01<00:00, 41.19it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43/74 [00:01<00:00, 44.95it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50/74 [00:01<00:00, 50.62it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57/74 [00:01<00:00, 54.72it/s][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64/74 [00:01<00:00, 58.22it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71/74 [00:01<00:00, 60.44it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 34.86it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:45:03,446 P708022 INFO [Metrics] AUC: 0.500000 - logloss: 8.002364
2025-05-09 00:45:03,447 P708022 INFO Monitor(max)=0.500000 STOP!
2025-05-09 00:45:03,447 P708022 INFO Reduce learning rate on plateau: 0.000100

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 591/591 [00:33<00:00, 17.73it/s]2025-05-09 00:45:03,548 P708022 INFO ************ Epoch=2 end ************

  0%|          | 0/591 [00:00<?, ?it/s]  0%|          | 1/591 [00:01<12:43,  1.29s/it]  1%|          | 3/591 [00:01<03:51,  2.54it/s]  1%|          | 5/591 [00:01<02:07,  4.60it/s]  1%|â–         | 8/591 [00:01<01:14,  7.84it/s]  2%|â–         | 11/591 [00:01<00:53, 10.81it/s]  2%|â–         | 14/591 [00:01<00:43, 13.18it/s]  3%|â–Ž         | 17/591 [00:02<00:37, 15.16it/s]  3%|â–Ž         | 20/591 [00:02<00:34, 16.60it/s]  4%|â–         | 23/591 [00:02<00:31, 17.85it/s]  4%|â–         | 26/591 [00:02<00:30, 18.76it/s]  5%|â–         | 29/591 [00:02<00:29, 19.36it/s]  5%|â–Œ         | 32/591 [00:02<00:28, 19.80it/s]  6%|â–Œ         | 35/591 [00:02<00:27, 20.19it/s]  6%|â–‹         | 38/591 [00:03<00:26, 20.55it/s]  7%|â–‹         | 41/591 [00:03<00:26, 20.42it/s]  7%|â–‹         | 44/591 [00:03<00:26, 20.71it/s]  8%|â–Š         | 47/591 [00:03<00:26, 20.53it/s]  8%|â–Š         | 50/591 [00:03<00:26, 20.64it/s]  9%|â–‰         | 53/591 [00:03<00:26, 20.10it/s]  9%|â–‰         | 56/591 [00:03<00:26, 20.43it/s] 10%|â–‰         | 59/591 [00:04<00:26, 20.34it/s] 10%|â–ˆ         | 62/591 [00:04<00:25, 20.69it/s] 11%|â–ˆ         | 65/591 [00:04<00:25, 20.62it/s] 12%|â–ˆâ–        | 68/591 [00:04<00:25, 20.66it/s] 12%|â–ˆâ–        | 71/591 [00:04<00:25, 20.43it/s] 13%|â–ˆâ–Ž        | 74/591 [00:04<00:25, 20.50it/s] 13%|â–ˆâ–Ž        | 77/591 [00:05<00:25, 19.92it/s] 14%|â–ˆâ–Ž        | 80/591 [00:05<00:25, 20.13it/s] 14%|â–ˆâ–        | 83/591 [00:05<00:25, 20.12it/s] 15%|â–ˆâ–        | 86/591 [00:05<00:26, 19.39it/s] 15%|â–ˆâ–Œ        | 89/591 [00:05<00:25, 19.83it/s] 16%|â–ˆâ–Œ        | 92/591 [00:05<00:24, 20.11it/s] 16%|â–ˆâ–Œ        | 95/591 [00:05<00:24, 20.33it/s] 17%|â–ˆâ–‹        | 98/591 [00:06<00:23, 20.62it/s] 17%|â–ˆâ–‹        | 101/591 [00:06<00:23, 20.52it/s] 18%|â–ˆâ–Š        | 104/591 [00:06<00:23, 20.57it/s] 18%|â–ˆâ–Š        | 107/591 [00:06<00:23, 20.55it/s] 19%|â–ˆâ–Š        | 110/591 [00:06<00:24, 19.86it/s] 19%|â–ˆâ–‰        | 113/591 [00:06<00:23, 20.14it/s] 20%|â–ˆâ–‰        | 116/591 [00:06<00:24, 19.67it/s] 20%|â–ˆâ–ˆ        | 119/591 [00:07<00:23, 19.99it/s] 21%|â–ˆâ–ˆ        | 122/591 [00:07<00:23, 20.11it/s] 21%|â–ˆâ–ˆ        | 125/591 [00:07<00:22, 20.36it/s] 22%|â–ˆâ–ˆâ–       | 128/591 [00:07<00:22, 20.42it/s] 22%|â–ˆâ–ˆâ–       | 131/591 [00:07<00:22, 20.50it/s] 23%|â–ˆâ–ˆâ–Ž       | 134/591 [00:07<00:22, 20.18it/s] 23%|â–ˆâ–ˆâ–Ž       | 137/591 [00:08<00:22, 20.09it/s] 24%|â–ˆâ–ˆâ–Ž       | 140/591 [00:08<00:22, 20.03it/s] 24%|â–ˆâ–ˆâ–       | 143/591 [00:08<00:22, 20.22it/s] 25%|â–ˆâ–ˆâ–       | 146/591 [00:08<00:21, 20.64it/s] 25%|â–ˆâ–ˆâ–Œ       | 149/591 [00:08<00:21, 20.51it/s] 26%|â–ˆâ–ˆâ–Œ       | 152/591 [00:08<00:21, 20.73it/s] 26%|â–ˆâ–ˆâ–Œ       | 155/591 [00:08<00:21, 19.88it/s] 27%|â–ˆâ–ˆâ–‹       | 158/591 [00:09<00:21, 19.92it/s] 27%|â–ˆâ–ˆâ–‹       | 161/591 [00:09<00:21, 20.10it/s] 28%|â–ˆâ–ˆâ–Š       | 164/591 [00:09<00:21, 19.89it/s] 28%|â–ˆâ–ˆâ–Š       | 167/591 [00:09<00:21, 20.09it/s] 29%|â–ˆâ–ˆâ–‰       | 170/591 [00:09<00:20, 20.35it/s] 29%|â–ˆâ–ˆâ–‰       | 173/591 [00:09<00:20, 20.07it/s] 30%|â–ˆâ–ˆâ–‰       | 176/591 [00:09<00:20, 20.21it/s] 30%|â–ˆâ–ˆâ–ˆ       | 179/591 [00:10<00:20, 20.39it/s] 31%|â–ˆâ–ˆâ–ˆ       | 182/591 [00:10<00:20, 20.42it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 185/591 [00:10<00:19, 20.52it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 188/591 [00:10<00:19, 20.22it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 191/591 [00:10<00:19, 20.42it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 194/591 [00:10<00:19, 20.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 197/591 [00:10<00:19, 20.57it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 200/591 [00:11<00:19, 19.78it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 202/591 [00:11<00:19, 19.81it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 204/591 [00:11<00:19, 19.71it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 207/591 [00:11<00:19, 20.06it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 210/591 [00:11<00:19, 19.35it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 213/591 [00:11<00:19, 19.78it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 216/591 [00:11<00:18, 20.11it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 219/591 [00:12<00:18, 20.42it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 222/591 [00:12<00:18, 20.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 225/591 [00:12<00:18, 19.89it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 228/591 [00:12<00:18, 20.03it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 231/591 [00:12<00:17, 20.18it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 234/591 [00:12<00:17, 19.94it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 237/591 [00:12<00:17, 19.99it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 240/591 [00:13<00:17, 19.97it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 243/591 [00:13<00:17, 20.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 246/591 [00:13<00:17, 19.86it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 248/591 [00:13<00:17, 19.83it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 250/591 [00:13<00:17, 19.86it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 252/591 [00:13<00:17, 19.79it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 255/591 [00:13<00:16, 20.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 258/591 [00:14<00:16, 20.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 261/591 [00:14<00:16, 20.46it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 264/591 [00:14<00:15, 20.56it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 267/591 [00:14<00:15, 20.75it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 270/591 [00:14<00:15, 20.66it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 273/591 [00:14<00:15, 20.65it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 276/591 [00:14<00:15, 20.77it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 279/591 [00:15<00:14, 20.80it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 282/591 [00:15<00:14, 20.65it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 285/591 [00:15<00:14, 20.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 288/591 [00:15<00:14, 20.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 291/591 [00:15<00:14, 20.88it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 294/591 [00:15<00:14, 20.84it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 297/591 [00:15<00:14, 20.83it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 300/591 [00:16<00:14, 20.76it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 303/591 [00:16<00:13, 20.76it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 306/591 [00:16<00:14, 20.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 309/591 [00:16<00:13, 20.40it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 312/591 [00:16<00:13, 20.28it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 315/591 [00:16<00:13, 20.43it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 318/591 [00:16<00:13, 20.44it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 321/591 [00:17<00:13, 20.74it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 324/591 [00:17<00:12, 20.87it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 327/591 [00:17<00:12, 20.94it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 330/591 [00:17<00:12, 20.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 333/591 [00:17<00:12, 20.39it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 336/591 [00:17<00:12, 20.55it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 339/591 [00:17<00:12, 20.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 342/591 [00:18<00:11, 21.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 345/591 [00:18<00:11, 20.57it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 348/591 [00:18<00:11, 20.38it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 351/591 [00:18<00:11, 20.39it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 354/591 [00:18<00:11, 20.42it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 357/591 [00:18<00:11, 20.36it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 360/591 [00:18<00:11, 20.36it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 363/591 [00:19<00:11, 20.25it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 366/591 [00:19<00:11, 20.45it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 369/591 [00:19<00:10, 20.60it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 372/591 [00:19<00:10, 20.24it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 375/591 [00:19<00:10, 20.16it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 378/591 [00:19<00:10, 20.08it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 381/591 [00:20<00:10, 19.81it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 383/591 [00:20<00:10, 19.65it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 385/591 [00:20<00:10, 19.64it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 387/591 [00:20<00:10, 19.67it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 390/591 [00:20<00:10, 19.87it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 393/591 [00:20<00:09, 20.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 396/591 [00:20<00:09, 20.11it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 399/591 [00:20<00:09, 19.95it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 401/591 [00:21<00:09, 19.75it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 403/591 [00:21<00:09, 19.09it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 405/591 [00:21<00:09, 18.86it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 407/591 [00:21<00:09, 18.61it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 409/591 [00:21<00:09, 18.80it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 411/591 [00:21<00:09, 18.92it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 413/591 [00:21<00:09, 18.95it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 415/591 [00:21<00:09, 19.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 417/591 [00:21<00:09, 18.93it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 420/591 [00:22<00:08, 19.71it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 423/591 [00:22<00:08, 19.98it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 426/591 [00:22<00:08, 20.25it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 429/591 [00:22<00:08, 20.22it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 432/591 [00:22<00:07, 20.11it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 435/591 [00:22<00:07, 19.93it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 438/591 [00:22<00:07, 19.26it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 441/591 [00:23<00:07, 19.60it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 444/591 [00:23<00:07, 19.87it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 447/591 [00:23<00:07, 19.78it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 449/591 [00:23<00:07, 19.37it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 452/591 [00:23<00:06, 19.88it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 454/591 [00:23<00:06, 19.86it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 456/591 [00:23<00:06, 19.88it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 459/591 [00:23<00:06, 20.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 462/591 [00:24<00:06, 20.17it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 465/591 [00:24<00:06, 19.96it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 468/591 [00:24<00:06, 20.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 471/591 [00:24<00:05, 20.15it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 474/591 [00:24<00:05, 20.18it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 477/591 [00:24<00:05, 20.15it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 480/591 [00:25<00:05, 19.18it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 482/591 [00:25<00:05, 18.48it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 484/591 [00:25<00:05, 18.46it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 487/591 [00:25<00:05, 19.12it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 489/591 [00:25<00:05, 18.95it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 491/591 [00:25<00:05, 18.36it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 493/591 [00:25<00:05, 18.64it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 495/591 [00:25<00:05, 18.91it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 497/591 [00:25<00:04, 19.20it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 499/591 [00:26<00:04, 19.21it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 501/591 [00:26<00:04, 19.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 503/591 [00:26<00:04, 18.58it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 506/591 [00:26<00:04, 19.13it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 509/591 [00:26<00:04, 19.45it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 511/591 [00:26<00:04, 19.58it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 513/591 [00:26<00:03, 19.58it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 515/591 [00:26<00:03, 19.50it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 517/591 [00:27<00:04, 17.63it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 519/591 [00:27<00:03, 18.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 521/591 [00:27<00:03, 18.33it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 524/591 [00:27<00:03, 18.84it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 526/591 [00:27<00:03, 19.10it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 528/591 [00:27<00:03, 19.17it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 531/591 [00:27<00:03, 19.47it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 533/591 [00:27<00:02, 19.44it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 535/591 [00:27<00:02, 19.22it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 538/591 [00:28<00:02, 19.52it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 540/591 [00:28<00:02, 18.64it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 542/591 [00:28<00:02, 18.76it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 544/591 [00:28<00:02, 19.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 547/591 [00:28<00:02, 19.38it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 550/591 [00:28<00:02, 19.68it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 552/591 [00:28<00:01, 19.65it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 555/591 [00:28<00:01, 19.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 557/591 [00:29<00:01, 19.16it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 559/591 [00:29<00:04,  7.86it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 562/591 [00:29<00:02, 10.18it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 565/591 [00:30<00:02, 12.37it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 568/591 [00:30<00:01, 14.25it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 571/591 [00:30<00:01, 16.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 574/591 [00:30<00:00, 17.54it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 577/591 [00:30<00:00, 18.42it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 580/591 [00:30<00:00, 18.87it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 583/591 [00:30<00:00, 19.50it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 586/591 [00:31<00:00, 19.70it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 589/591 [00:31<00:00, 20.09it/s]2025-05-09 00:45:34,810 P708022 INFO Train loss: 49.648280
2025-05-09 00:45:34,811 P708022 INFO Evaluation @epoch 3 - batch 591: 

  0%|          | 0/74 [00:00<?, ?it/s][A
  1%|â–         | 1/74 [00:00<00:56,  1.29it/s][A
  7%|â–‹         | 5/74 [00:00<00:09,  7.21it/s][A
 15%|â–ˆâ–        | 11/74 [00:00<00:03, 16.44it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 17/74 [00:01<00:02, 25.00it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 23/74 [00:01<00:01, 32.29it/s][A
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 29/74 [00:01<00:01, 37.65it/s][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35/74 [00:01<00:00, 42.28it/s][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/74 [00:01<00:00, 45.44it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47/74 [00:01<00:00, 49.25it/s][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54/74 [00:01<00:00, 53.57it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60/74 [00:01<00:00, 53.82it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66/74 [00:01<00:00, 55.41it/s][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73/74 [00:02<00:00, 56.81it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 33.92it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:45:38,109 P708022 INFO [Metrics] AUC: 0.500000 - logloss: 8.002364
2025-05-09 00:45:38,114 P708022 INFO Monitor(max)=0.500000 STOP!
2025-05-09 00:45:38,114 P708022 INFO Reduce learning rate on plateau: 0.000010
2025-05-09 00:45:38,114 P708022 INFO ********* Epoch=3 early stop *********

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 590/591 [00:34<00:00, 17.01it/s]2025-05-09 00:45:38,236 P708022 INFO Training finished.
2025-05-09 00:45:38,236 P708022 INFO Load best model: /home/dxlab/jupyter/jinhee/scv/checkpoints/KKBox_x1/EulerNet_KKBox_x1.model
/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/fuxictr/pytorch/models/rank_model.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(checkpoint, map_location="cpu")
2025-05-09 00:45:38,297 P708022 INFO ****** Validation evaluation ******

  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<01:00,  1.20it/s]  5%|â–Œ         | 4/74 [00:00<00:13,  5.23it/s] 14%|â–ˆâ–Ž        | 10/74 [00:01<00:04, 14.23it/s] 22%|â–ˆâ–ˆâ–       | 16/74 [00:01<00:02, 22.49it/s] 28%|â–ˆâ–ˆâ–Š       | 21/74 [00:01<00:01, 28.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 27/74 [00:01<00:01, 34.89it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/74 [00:01<00:01, 39.48it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39/74 [00:01<00:00, 42.69it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45/74 [00:01<00:00, 45.92it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52/74 [00:01<00:00, 50.31it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58/74 [00:01<00:00, 52.83it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64/74 [00:02<00:00, 54.17it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70/74 [00:02<00:00, 55.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 32.07it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:45:41,445 P708022 INFO [Metrics] logloss: 0.551629 - AUC: 0.794247
2025-05-09 00:45:41,630 P708022 INFO ******** Test evaluation ********
2025-05-09 00:45:41,631 P708022 INFO Loading datasets...
2025-05-09 00:45:45,877 P708022 INFO Test samples: total/737743, blocks/1
2025-05-09 00:45:45,877 P708022 INFO Loading test data done.

  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<01:06,  1.09it/s]  5%|â–Œ         | 4/74 [00:01<00:14,  4.93it/s] 12%|â–ˆâ–        | 9/74 [00:01<00:07,  8.74it/s] 15%|â–ˆâ–        | 11/74 [00:01<00:07,  7.88it/s] 20%|â–ˆâ–ˆ        | 15/74 [00:02<00:06,  8.68it/s] 28%|â–ˆâ–ˆâ–Š       | 21/74 [00:02<00:03, 14.55it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 27/74 [00:02<00:02, 20.83it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/74 [00:02<00:01, 22.66it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/74 [00:02<00:01, 27.16it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42/74 [00:02<00:00, 33.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/74 [00:02<00:00, 38.89it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/74 [00:02<00:00, 45.12it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/74 [00:02<00:00, 50.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69/74 [00:03<00:00, 54.74it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:03<00:00, 22.42it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:45:49,969 P708022 INFO [Metrics] logloss: 0.551425 - AUC: 0.794378
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<01:08,  1.06it/s]  3%|â–Ž         | 2/74 [00:01<00:42,  1.69it/s]  4%|â–         | 3/74 [00:01<00:26,  2.66it/s] 12%|â–ˆâ–        | 9/74 [00:01<00:05, 11.06it/s] 19%|â–ˆâ–‰        | 14/74 [00:01<00:03, 17.55it/s] 27%|â–ˆâ–ˆâ–‹       | 20/74 [00:01<00:02, 25.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 27/74 [00:01<00:01, 33.65it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/74 [00:01<00:01, 39.30it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39/74 [00:02<00:00, 43.51it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45/74 [00:02<00:00, 46.70it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51/74 [00:02<00:00, 50.18it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57/74 [00:02<00:00, 52.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64/74 [00:02<00:00, 54.08it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70/74 [00:02<00:00, 55.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 26.55it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:45:53,553 P708022 INFO [Metrics] logloss: 0.551426 - AUC: 0.794378
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.0 OrderedDict([('logloss', 0.5514256282686686), ('AUC', 0.7943780700245728)]) tensor(129., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<01:05,  1.12it/s]  3%|â–Ž         | 2/74 [00:01<00:45,  1.57it/s]  9%|â–‰         | 7/74 [00:01<00:09,  7.19it/s] 18%|â–ˆâ–Š        | 13/74 [00:01<00:04, 14.35it/s] 24%|â–ˆâ–ˆâ–       | 18/74 [00:01<00:02, 20.20it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 24/74 [00:01<00:01, 27.44it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/74 [00:01<00:01, 33.83it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/74 [00:01<00:00, 39.46it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42/74 [00:02<00:00, 43.16it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/74 [00:02<00:00, 47.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54/74 [00:02<00:00, 50.18it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/74 [00:02<00:00, 53.44it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67/74 [00:02<00:00, 54.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 56.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 26.93it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:45:58,200 P708022 INFO [Metrics] logloss: 0.549965 - AUC: 0.793331
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.1 OrderedDict([('logloss', 0.5499650648618714), ('AUC', 0.7933309339431036)]) tensor(117., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<01:01,  1.19it/s]  5%|â–Œ         | 4/74 [00:01<00:16,  4.15it/s] 14%|â–ˆâ–Ž        | 10/74 [00:01<00:05, 11.64it/s] 18%|â–ˆâ–Š        | 13/74 [00:01<00:04, 12.33it/s] 22%|â–ˆâ–ˆâ–       | 16/74 [00:01<00:05, 11.57it/s] 30%|â–ˆâ–ˆâ–‰       | 22/74 [00:01<00:02, 18.68it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/74 [00:01<00:01, 25.85it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/74 [00:02<00:01, 30.22it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39/74 [00:02<00:00, 35.80it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45/74 [00:02<00:00, 40.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51/74 [00:02<00:00, 44.34it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58/74 [00:02<00:00, 50.75it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64/74 [00:02<00:00, 52.35it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70/74 [00:02<00:00, 53.82it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 25.36it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:46:03,525 P708022 INFO [Metrics] logloss: 0.550187 - AUC: 0.793044
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.2 OrderedDict([('logloss', 0.5501869760915504), ('AUC', 0.7930442666744708)]) tensor(104., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<01:03,  1.15it/s]  4%|â–         | 3/74 [00:01<00:21,  3.27it/s]  9%|â–‰         | 7/74 [00:01<00:07,  8.66it/s] 18%|â–ˆâ–Š        | 13/74 [00:01<00:03, 17.38it/s] 26%|â–ˆâ–ˆâ–Œ       | 19/74 [00:01<00:02, 25.37it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 25/74 [00:01<00:01, 32.00it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/74 [00:01<00:01, 37.71it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/74 [00:01<00:01, 34.50it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/74 [00:02<00:01, 28.76it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/74 [00:02<00:00, 36.16it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54/74 [00:02<00:00, 40.70it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/74 [00:02<00:00, 46.21it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/74 [00:02<00:00, 51.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 27.48it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:46:07,665 P708022 INFO [Metrics] logloss: 0.550025 - AUC: 0.792906
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.30000000000000004 OrderedDict([('logloss', 0.5500246823162388), ('AUC', 0.7929056632168541)]) tensor(91., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<01:03,  1.15it/s]  7%|â–‹         | 5/74 [00:00<00:10,  6.60it/s] 14%|â–ˆâ–Ž        | 10/74 [00:01<00:04, 13.47it/s] 22%|â–ˆâ–ˆâ–       | 16/74 [00:01<00:03, 14.71it/s] 27%|â–ˆâ–ˆâ–‹       | 20/74 [00:01<00:03, 14.89it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/74 [00:01<00:02, 21.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32/74 [00:01<00:01, 27.39it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/74 [00:02<00:01, 24.89it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42/74 [00:02<00:01, 30.82it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/74 [00:02<00:00, 36.50it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53/74 [00:02<00:00, 39.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60/74 [00:02<00:00, 45.53it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67/74 [00:02<00:00, 50.25it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73/74 [00:02<00:00, 51.75it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 25.22it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:46:12,105 P708022 INFO [Metrics] logloss: 0.549958 - AUC: 0.793003
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.4 OrderedDict([('logloss', 0.5499577314127113), ('AUC', 0.7930026088483275)]) tensor(78., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:58,  1.25it/s]  4%|â–         | 3/74 [00:01<00:23,  3.03it/s]  5%|â–Œ         | 4/74 [00:01<00:21,  3.24it/s] 14%|â–ˆâ–Ž        | 10/74 [00:01<00:05, 10.78it/s] 18%|â–ˆâ–Š        | 13/74 [00:01<00:04, 13.82it/s] 26%|â–ˆâ–ˆâ–Œ       | 19/74 [00:01<00:02, 21.93it/s] 31%|â–ˆâ–ˆâ–ˆ       | 23/74 [00:01<00:02, 22.80it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/74 [00:02<00:01, 27.90it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32/74 [00:02<00:01, 30.53it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/74 [00:02<00:01, 31.94it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/74 [00:02<00:00, 36.25it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47/74 [00:02<00:00, 41.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54/74 [00:02<00:00, 47.08it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/74 [00:02<00:00, 52.10it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/74 [00:02<00:00, 55.71it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 56.67it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 24.77it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:46:16,679 P708022 INFO [Metrics] logloss: 0.549107 - AUC: 0.792261
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.5 OrderedDict([('logloss', 0.549107236878949), ('AUC', 0.7922610689115123)]) tensor(65., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<01:05,  1.11it/s]  3%|â–Ž         | 2/74 [00:01<00:46,  1.55it/s]  8%|â–Š         | 6/74 [00:01<00:11,  5.96it/s] 16%|â–ˆâ–Œ        | 12/74 [00:01<00:04, 13.41it/s] 24%|â–ˆâ–ˆâ–       | 18/74 [00:01<00:02, 20.64it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 24/74 [00:01<00:01, 27.73it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/74 [00:01<00:01, 33.89it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/74 [00:02<00:00, 39.13it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42/74 [00:02<00:00, 42.63it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/74 [00:02<00:00, 45.67it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54/74 [00:02<00:00, 44.19it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60/74 [00:02<00:00, 46.65it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66/74 [00:02<00:00, 48.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72/74 [00:02<00:00, 48.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 24.92it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:46:21,772 P708022 INFO [Metrics] logloss: 0.549112 - AUC: 0.792256
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.6000000000000001 OrderedDict([('logloss', 0.549112174729882), ('AUC', 0.7922555279477022)]) tensor(52., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<01:01,  1.18it/s]  3%|â–Ž         | 2/74 [00:01<00:44,  1.63it/s]  9%|â–‰         | 7/74 [00:01<00:09,  7.37it/s] 18%|â–ˆâ–Š        | 13/74 [00:01<00:04, 14.86it/s] 26%|â–ˆâ–ˆâ–Œ       | 19/74 [00:01<00:02, 22.06it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 25/74 [00:01<00:01, 28.87it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/74 [00:01<00:01, 34.78it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/74 [00:01<00:00, 39.56it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43/74 [00:02<00:00, 42.57it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50/74 [00:02<00:00, 47.90it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57/74 [00:02<00:00, 51.39it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64/74 [00:02<00:00, 54.42it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71/74 [00:02<00:00, 57.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 27.39it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:46:25,233 P708022 INFO [Metrics] logloss: 0.549402 - AUC: 0.792042
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.7000000000000001 OrderedDict([('logloss', 0.5494017188734847), ('AUC', 0.7920423270597365)]) tensor(39., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<01:08,  1.06it/s]  5%|â–Œ         | 4/74 [00:01<00:21,  3.28it/s] 12%|â–ˆâ–        | 9/74 [00:01<00:07,  8.41it/s] 20%|â–ˆâ–ˆ        | 15/74 [00:01<00:03, 15.34it/s] 28%|â–ˆâ–ˆâ–Š       | 21/74 [00:01<00:02, 22.36it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 27/74 [00:01<00:01, 28.89it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34/74 [00:01<00:01, 36.20it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/74 [00:02<00:00, 42.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/74 [00:02<00:00, 48.13it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/74 [00:02<00:00, 53.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/74 [00:02<00:00, 57.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69/74 [00:02<00:00, 59.29it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 27.56it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:46:28,604 P708022 INFO [Metrics] logloss: 0.549705 - AUC: 0.791748
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.8 OrderedDict([('logloss', 0.5497046683498337), ('AUC', 0.7917481137736514)]) tensor(26., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:55,  1.30it/s]  5%|â–Œ         | 4/74 [00:01<00:16,  4.27it/s] 11%|â–ˆ         | 8/74 [00:01<00:09,  7.03it/s] 14%|â–ˆâ–Ž        | 10/74 [00:01<00:08,  7.11it/s] 22%|â–ˆâ–ˆâ–       | 16/74 [00:01<00:04, 14.03it/s] 28%|â–ˆâ–ˆâ–Š       | 21/74 [00:01<00:02, 19.34it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 25/74 [00:02<00:02, 18.26it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/74 [00:02<00:01, 25.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/74 [00:02<00:01, 30.71it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42/74 [00:02<00:00, 34.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/74 [00:02<00:00, 40.15it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/74 [00:02<00:00, 46.37it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/74 [00:02<00:00, 49.72it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/74 [00:02<00:00, 53.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:03<00:00, 23.65it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:46:33,037 P708022 INFO [Metrics] logloss: 0.550114 - AUC: 0.791699
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.9 OrderedDict([('logloss', 0.5501142450768088), ('AUC', 0.7916985429360742)]) tensor(13., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:59,  1.22it/s]  5%|â–Œ         | 4/74 [00:00<00:12,  5.39it/s] 14%|â–ˆâ–Ž        | 10/74 [00:01<00:04, 14.35it/s] 19%|â–ˆâ–‰        | 14/74 [00:01<00:04, 12.29it/s] 26%|â–ˆâ–ˆâ–Œ       | 19/74 [00:01<00:04, 12.33it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 25/74 [00:01<00:02, 18.30it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/74 [00:02<00:01, 22.89it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35/74 [00:02<00:01, 25.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40/74 [00:02<00:01, 29.14it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47/74 [00:02<00:00, 36.63it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53/74 [00:02<00:00, 40.83it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60/74 [00:02<00:00, 46.71it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67/74 [00:02<00:00, 51.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 54.59it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:03<00:00, 24.44it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:46:36,866 P708022 INFO [Metrics] logloss: 0.550186 - AUC: 0.791622
2025-05-09 00:46:36,873 P708022 INFO ******** Remove Model Weights ********

1.0 OrderedDict([('logloss', 0.5501856265288362), ('AUC', 0.7916221080369116)]) tensor(0., device='cuda:1')
