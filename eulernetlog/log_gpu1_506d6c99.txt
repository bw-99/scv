2025-05-09 00:36:21,393 P659171 INFO FuxiCTR version: 2.3.3
2025-05-09 00:36:21,393 P659171 INFO Params: {
    "batch_size": "10000",
    "data_format": "csv",
    "data_root": "dataset/",
    "dataset_id": "KKBox_x1",
    "debug_mode": "False",
    "early_stop_patience": "2",
    "embedding_dim": "128",
    "embedding_regularizer": "0.0005",
    "epochs": "100",
    "eval_steps": "None",
    "experiment_id": "EulerNet_KKBox_x1",
    "feature_cols": "[{'active': True, 'dtype': 'str', 'name': ['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', 'city', 'gender', 'registered_via', 'language'], 'type': 'categorical'}, {'active': True, 'dtype': 'str', 'encoder': 'MaskedSumPooling', 'max_len': 3, 'name': 'genre_ids', 'type': 'sequence'}, {'active': True, 'dtype': 'str', 'encoder': 'MaskedSumPooling', 'max_len': 3, 'name': 'artist_name', 'type': 'sequence'}, {'active': True, 'dtype': 'str', 'name': 'isrc', 'preprocess': 'extract_country_code', 'type': 'categorical'}, {'active': True, 'dtype': 'str', 'name': 'bd', 'preprocess': 'bucketize_age', 'type': 'categorical'}]",
    "feature_config": "None",
    "feature_specs": "None",
    "gpu": "1",
    "group_id": "None",
    "label_col": "{'dtype': 'float', 'name': 'label'}",
    "layer_norm": "True",
    "learning_rate": "0.001",
    "loss": "binary_crossentropy",
    "mask_rate": "0",
    "metrics": "['logloss', 'AUC']",
    "min_categr_count": "10",
    "model": "EulerNet",
    "model_id": "EulerNet_KKBox_x1",
    "model_root": "./checkpoints/",
    "monitor": "{'AUC': 1, 'logloss': 0}",
    "monitor_mode": "max",
    "net_ex_dropout": "0.2",
    "net_im_dropout": "0",
    "num_workers": "16",
    "optimizer": "adam",
    "pickle_feature_encoder": "True",
    "save_best_only": "True",
    "save_feature_interaction": "0",
    "seed": "2024",
    "shape": "[10, 10]",
    "task": "binary_classification",
    "test_data": "dataset/KKBox_x1/test.csv",
    "train_data": "dataset/KKBox_x1/train.csv",
    "use_features": "None",
    "valid_data": "dataset/KKBox_x1/valid.csv",
    "verbose": "1"
}
2025-05-09 00:36:21,393 P659171 INFO Set up feature processor...
2025-05-09 00:36:21,393 P659171 WARNING Skip rebuilding dataset/KKBox_x1/feature_map.json. Please delete it manually if rebuilding is required.
2025-05-09 00:36:21,393 P659171 INFO Load feature_map from json: dataset/KKBox_x1/feature_map.json
2025-05-09 00:36:21,393 P659171 INFO Set column index...
2025-05-09 00:36:21,393 P659171 INFO Feature specs: {
    "artist_name": "{'source': '', 'type': 'sequence', 'feature_encoder': 'layers.MaskedAveragePooling()', 'padding_idx': 0, 'max_len': 3, 'vocab_size': 11976}",
    "bd": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 9}",
    "city": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 23}",
    "gender": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 4}",
    "genre_ids": "{'source': '', 'type': 'sequence', 'feature_encoder': 'layers.MaskedAveragePooling()', 'padding_idx': 0, 'max_len': 3, 'vocab_size': 346}",
    "isrc": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 80}",
    "language": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 12}",
    "msno": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 25963}",
    "registered_via": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 7}",
    "song_id": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 53291}",
    "source_screen_name": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 21}",
    "source_system_tab": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 10}",
    "source_type": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 14}"
}
/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/fuxictr/pytorch/models/rank_model.py:65: UserWarning: mods argument is not needed anymore, you can stop passing it
  self.flop_counter = FlopCounterMode(mods=self, display=False, depth=None)
2025-05-09 00:36:22,436 P659171 INFO Total number of parameters: 3778548.
2025-05-09 00:36:22,436 P659171 INFO Total number of parameters: 15523316.
2025-05-09 00:36:22,436 P659171 INFO Loading datasets...
2025-05-09 00:36:42,185 P659171 INFO Train samples: total/5901932, blocks/1
2025-05-09 00:36:44,671 P659171 INFO Validation samples: total/737743, blocks/1
2025-05-09 00:36:44,672 P659171 INFO Loading train and validation data done.
2025-05-09 00:36:44,672 P659171 INFO Start training: 591 batches/epoch
2025-05-09 00:36:44,672 P659171 INFO ************ Epoch=1 start ************
remove_modelremove_modelremove_modelremove_modelremove_modelremove_modelremove_modelremove_modelremove_modelremove_model True
**************
./config/ EulerNet_KKBox_x1
**************
EulerNet_KKBox_x1
*******************
dataset/KKBox_x1
fucking {'active': True, 'dtype': 'str', 'name': ['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', 'city', 'gender', 'registered_via', 'language'], 'type': 'categorical'}
fucking {'active': True, 'dtype': 'str', 'encoder': 'MaskedSumPooling', 'max_len': 3, 'name': 'genre_ids', 'type': 'sequence'}
fucking {'active': True, 'dtype': 'str', 'encoder': 'MaskedSumPooling', 'max_len': 3, 'name': 'artist_name', 'type': 'sequence'}
fucking {'active': True, 'dtype': 'str', 'name': 'isrc', 'preprocess': 'extract_country_code', 'type': 'categorical'}
fucking {'active': True, 'dtype': 'str', 'name': 'bd', 'preprocess': 'bucketize_age', 'type': 'categorical'}
mask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is none
mask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is nonemask is none
without emb dim
  0%|          | 0/591 [00:00<?, ?it/s]  0%|          | 1/591 [00:02<21:30,  2.19s/it]  1%|          | 4/591 [00:02<04:25,  2.21it/s]  1%|          | 7/591 [00:02<02:16,  4.27it/s]  2%|â–         | 9/591 [00:02<01:40,  5.79it/s]  2%|â–         | 11/591 [00:02<01:17,  7.44it/s]  2%|â–         | 14/591 [00:02<00:56, 10.21it/s]  3%|â–Ž         | 16/591 [00:02<00:52, 11.03it/s]  3%|â–Ž         | 19/591 [00:03<00:42, 13.60it/s]  4%|â–Ž         | 22/591 [00:03<00:36, 15.69it/s]  4%|â–         | 25/591 [00:03<00:32, 17.34it/s]  5%|â–         | 28/591 [00:03<00:30, 18.55it/s]  5%|â–Œ         | 31/591 [00:03<00:28, 19.63it/s]  6%|â–Œ         | 34/591 [00:03<00:27, 19.97it/s]  6%|â–‹         | 37/591 [00:03<00:27, 20.42it/s]  7%|â–‹         | 40/591 [00:04<00:26, 20.71it/s]  7%|â–‹         | 43/591 [00:04<00:26, 20.83it/s]  8%|â–Š         | 46/591 [00:04<00:26, 20.61it/s]  8%|â–Š         | 49/591 [00:04<00:26, 20.77it/s]  9%|â–‰         | 52/591 [00:04<00:25, 20.94it/s]  9%|â–‰         | 55/591 [00:04<00:25, 21.09it/s] 10%|â–‰         | 58/591 [00:04<00:25, 20.94it/s] 10%|â–ˆ         | 61/591 [00:05<00:25, 21.07it/s] 11%|â–ˆ         | 64/591 [00:05<00:25, 20.71it/s] 11%|â–ˆâ–        | 67/591 [00:05<00:25, 20.81it/s] 12%|â–ˆâ–        | 70/591 [00:05<00:25, 20.75it/s] 12%|â–ˆâ–        | 73/591 [00:05<00:24, 20.81it/s] 13%|â–ˆâ–Ž        | 76/591 [00:05<00:24, 20.95it/s] 13%|â–ˆâ–Ž        | 79/591 [00:05<00:24, 21.04it/s] 14%|â–ˆâ–        | 82/591 [00:06<00:24, 21.09it/s] 14%|â–ˆâ–        | 85/591 [00:06<00:24, 21.04it/s] 15%|â–ˆâ–        | 88/591 [00:06<00:24, 20.76it/s] 15%|â–ˆâ–Œ        | 91/591 [00:06<00:23, 20.96it/s] 16%|â–ˆâ–Œ        | 94/591 [00:06<00:23, 21.08it/s] 16%|â–ˆâ–‹        | 97/591 [00:06<00:23, 21.13it/s] 17%|â–ˆâ–‹        | 100/591 [00:06<00:23, 21.08it/s] 17%|â–ˆâ–‹        | 103/591 [00:07<00:22, 21.23it/s] 18%|â–ˆâ–Š        | 106/591 [00:07<00:22, 21.40it/s] 18%|â–ˆâ–Š        | 109/591 [00:07<00:22, 21.24it/s] 19%|â–ˆâ–‰        | 112/591 [00:07<00:22, 21.25it/s] 19%|â–ˆâ–‰        | 115/591 [00:07<00:22, 21.29it/s] 20%|â–ˆâ–‰        | 118/591 [00:07<00:22, 21.27it/s] 20%|â–ˆâ–ˆ        | 121/591 [00:07<00:22, 20.93it/s] 21%|â–ˆâ–ˆ        | 124/591 [00:08<00:22, 20.76it/s] 21%|â–ˆâ–ˆâ–       | 127/591 [00:08<00:22, 20.71it/s] 22%|â–ˆâ–ˆâ–       | 130/591 [00:08<00:22, 20.90it/s] 23%|â–ˆâ–ˆâ–Ž       | 133/591 [00:08<00:21, 21.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 136/591 [00:08<00:21, 21.45it/s] 24%|â–ˆâ–ˆâ–Ž       | 139/591 [00:08<00:21, 21.48it/s] 24%|â–ˆâ–ˆâ–       | 142/591 [00:08<00:20, 21.40it/s] 25%|â–ˆâ–ˆâ–       | 145/591 [00:09<00:20, 21.36it/s] 25%|â–ˆâ–ˆâ–Œ       | 148/591 [00:09<00:20, 21.35it/s] 26%|â–ˆâ–ˆâ–Œ       | 151/591 [00:09<00:20, 21.47it/s] 26%|â–ˆâ–ˆâ–Œ       | 154/591 [00:09<00:20, 21.42it/s] 27%|â–ˆâ–ˆâ–‹       | 157/591 [00:09<00:20, 21.25it/s] 27%|â–ˆâ–ˆâ–‹       | 160/591 [00:09<00:20, 21.28it/s] 28%|â–ˆâ–ˆâ–Š       | 163/591 [00:09<00:20, 21.23it/s] 28%|â–ˆâ–ˆâ–Š       | 166/591 [00:10<00:19, 21.32it/s] 29%|â–ˆâ–ˆâ–Š       | 169/591 [00:10<00:19, 21.30it/s] 29%|â–ˆâ–ˆâ–‰       | 172/591 [00:10<00:19, 21.26it/s] 30%|â–ˆâ–ˆâ–‰       | 175/591 [00:10<00:19, 21.25it/s] 30%|â–ˆâ–ˆâ–ˆ       | 178/591 [00:10<00:19, 21.37it/s] 31%|â–ˆâ–ˆâ–ˆ       | 181/591 [00:10<00:19, 21.34it/s] 31%|â–ˆâ–ˆâ–ˆ       | 184/591 [00:10<00:19, 21.13it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 187/591 [00:11<00:19, 21.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 190/591 [00:11<00:18, 21.30it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 193/591 [00:11<00:18, 21.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 196/591 [00:11<00:18, 21.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 199/591 [00:11<00:18, 21.32it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 202/591 [00:11<00:18, 21.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 205/591 [00:11<00:18, 21.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 208/591 [00:12<00:18, 21.16it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 211/591 [00:12<00:17, 21.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 214/591 [00:12<00:17, 21.26it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 217/591 [00:12<00:17, 21.25it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 220/591 [00:12<00:17, 21.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 223/591 [00:12<00:17, 20.95it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 226/591 [00:12<00:17, 21.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 229/591 [00:13<00:17, 21.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 232/591 [00:13<00:16, 21.28it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 235/591 [00:13<00:17, 20.84it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 238/591 [00:13<00:16, 21.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 241/591 [00:13<00:16, 21.14it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 244/591 [00:13<00:16, 21.43it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 247/591 [00:13<00:15, 21.55it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 250/591 [00:13<00:15, 21.40it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 253/591 [00:14<00:15, 21.25it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 256/591 [00:14<00:15, 21.32it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 259/591 [00:14<00:15, 21.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 262/591 [00:14<00:15, 21.13it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 265/591 [00:14<00:15, 21.18it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 268/591 [00:14<00:15, 20.87it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 271/591 [00:14<00:15, 21.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 274/591 [00:15<00:15, 21.12it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 277/591 [00:15<00:14, 21.16it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 280/591 [00:15<00:15, 20.73it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 283/591 [00:15<00:14, 20.87it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 286/591 [00:15<00:14, 21.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 289/591 [00:15<00:14, 20.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 292/591 [00:15<00:14, 21.13it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 295/591 [00:16<00:14, 20.97it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 298/591 [00:16<00:13, 21.14it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 301/591 [00:16<00:13, 21.28it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 304/591 [00:16<00:13, 21.45it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 307/591 [00:16<00:13, 21.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 310/591 [00:16<00:13, 21.26it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 313/591 [00:16<00:13, 21.36it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 316/591 [00:17<00:12, 21.52it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 319/591 [00:17<00:12, 21.64it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 322/591 [00:17<00:12, 21.66it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 325/591 [00:17<00:12, 21.65it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 328/591 [00:17<00:12, 21.61it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 331/591 [00:17<00:12, 21.63it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 334/591 [00:17<00:11, 21.67it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 337/591 [00:18<00:11, 21.62it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 340/591 [00:18<00:11, 21.54it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 343/591 [00:18<00:11, 21.44it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 346/591 [00:18<00:11, 21.59it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 349/591 [00:18<00:11, 21.68it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 352/591 [00:18<00:11, 21.67it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 355/591 [00:18<00:11, 21.13it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 358/591 [00:19<00:10, 21.27it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 361/591 [00:19<00:10, 21.37it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 364/591 [00:19<00:10, 21.50it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 367/591 [00:19<00:10, 21.42it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 370/591 [00:19<00:10, 21.44it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 373/591 [00:19<00:10, 20.81it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 376/591 [00:19<00:10, 20.91it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 379/591 [00:20<00:10, 20.89it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 382/591 [00:20<00:10, 20.82it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 385/591 [00:20<00:09, 20.76it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 388/591 [00:20<00:09, 20.72it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 391/591 [00:20<00:09, 20.92it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 394/591 [00:20<00:09, 21.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 397/591 [00:20<00:09, 21.10it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 400/591 [00:21<00:09, 21.01it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 403/591 [00:21<00:09, 20.86it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 406/591 [00:21<00:08, 20.88it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 409/591 [00:21<00:08, 20.73it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 412/591 [00:21<00:08, 20.91it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 415/591 [00:21<00:08, 20.93it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 418/591 [00:21<00:08, 21.05it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 421/591 [00:22<00:08, 21.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 424/591 [00:22<00:07, 20.93it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 427/591 [00:22<00:07, 20.95it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 430/591 [00:22<00:07, 20.75it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 433/591 [00:22<00:07, 20.77it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 436/591 [00:22<00:07, 20.65it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 439/591 [00:22<00:07, 20.75it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 442/591 [00:23<00:07, 20.43it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 445/591 [00:23<00:07, 20.70it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 448/591 [00:23<00:06, 20.89it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 451/591 [00:23<00:06, 21.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 454/591 [00:23<00:06, 21.13it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 457/591 [00:23<00:06, 21.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 460/591 [00:23<00:06, 21.17it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 463/591 [00:24<00:05, 21.46it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 466/591 [00:24<00:05, 21.42it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 469/591 [00:24<00:05, 21.23it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 472/591 [00:24<00:05, 21.18it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 475/591 [00:24<00:05, 21.19it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 478/591 [00:24<00:05, 21.23it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 481/591 [00:24<00:05, 20.90it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 484/591 [00:25<00:05, 20.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 487/591 [00:25<00:04, 20.92it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 490/591 [00:25<00:04, 21.17it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 493/591 [00:25<00:04, 21.10it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 496/591 [00:25<00:04, 21.07it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 499/591 [00:25<00:04, 21.11it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 502/591 [00:25<00:04, 21.20it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 505/591 [00:26<00:04, 21.20it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 508/591 [00:26<00:03, 21.11it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 511/591 [00:26<00:03, 21.06it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 514/591 [00:26<00:03, 21.04it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 517/591 [00:26<00:03, 21.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 520/591 [00:26<00:03, 21.21it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 523/591 [00:26<00:03, 21.17it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 526/591 [00:27<00:03, 21.11it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 529/591 [00:27<00:02, 20.85it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 532/591 [00:27<00:02, 20.90it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 535/591 [00:27<00:02, 20.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 538/591 [00:27<00:02, 20.94it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 541/591 [00:27<00:02, 20.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 544/591 [00:27<00:02, 21.06it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 547/591 [00:28<00:02, 20.90it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 550/591 [00:28<00:01, 21.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 553/591 [00:28<00:01, 21.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 556/591 [00:28<00:01, 21.34it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 559/591 [00:29<00:03, 10.48it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 562/591 [00:29<00:02, 12.37it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 565/591 [00:29<00:01, 14.13it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 568/591 [00:29<00:01, 15.75it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 571/591 [00:29<00:01, 17.23it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 574/591 [00:29<00:00, 18.37it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 577/591 [00:29<00:00, 19.29it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 580/591 [00:30<00:00, 20.10it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 583/591 [00:30<00:00, 20.83it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 586/591 [00:30<00:00, 21.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 589/591 [00:30<00:00, 21.44it/s]2025-05-09 00:37:15,218 P659171 INFO Train loss: 49.567552
2025-05-09 00:37:15,219 P659171 INFO Evaluation @epoch 1 - batch 591: 

  0%|          | 0/74 [00:00<?, ?it/s][A
  1%|â–         | 1/74 [00:00<00:56,  1.29it/s][A
  5%|â–Œ         | 4/74 [00:00<00:12,  5.64it/s][A
 14%|â–ˆâ–Ž        | 10/74 [00:00<00:04, 15.31it/s][A
 22%|â–ˆâ–ˆâ–       | 16/74 [00:01<00:02, 22.84it/s][A
 30%|â–ˆâ–ˆâ–‰       | 22/74 [00:01<00:01, 30.67it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/74 [00:01<00:01, 37.25it/s][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35/74 [00:01<00:00, 43.51it/s][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/74 [00:01<00:00, 47.32it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/74 [00:01<00:00, 52.63it/s][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/74 [00:01<00:00, 56.56it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/74 [00:01<00:00, 59.64it/s][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69/74 [00:01<00:00, 61.71it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 34.99it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:37:17,840 P659171 INFO [Metrics] AUC: 0.500000 - logloss: 8.002364
2025-05-09 00:37:17,842 P659171 INFO Save best model: monitor(max)=0.500000

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 591/591 [00:33<00:00, 17.72it/s]2025-05-09 00:37:18,017 P659171 INFO ************ Epoch=1 end ************

  0%|          | 0/591 [00:00<?, ?it/s]  0%|          | 1/591 [00:01<13:11,  1.34s/it]  1%|          | 4/591 [00:01<02:51,  3.42it/s]  1%|          | 7/591 [00:01<01:33,  6.27it/s]  2%|â–         | 10/591 [00:01<01:04,  9.04it/s]  2%|â–         | 13/591 [00:01<00:50, 11.44it/s]  3%|â–Ž         | 16/591 [00:02<00:41, 13.81it/s]  3%|â–Ž         | 19/591 [00:02<00:36, 15.68it/s]  4%|â–Ž         | 22/591 [00:02<00:32, 17.31it/s]  4%|â–         | 25/591 [00:02<00:30, 18.64it/s]  5%|â–         | 28/591 [00:02<00:28, 19.50it/s]  5%|â–Œ         | 31/591 [00:02<00:27, 20.27it/s]  6%|â–Œ         | 34/591 [00:02<00:26, 20.64it/s]  6%|â–‹         | 37/591 [00:03<00:26, 20.94it/s]  7%|â–‹         | 40/591 [00:03<00:26, 21.19it/s]  7%|â–‹         | 43/591 [00:03<00:25, 21.39it/s]  8%|â–Š         | 46/591 [00:03<00:25, 21.30it/s]  8%|â–Š         | 49/591 [00:03<00:25, 21.54it/s]  9%|â–‰         | 52/591 [00:03<00:24, 21.61it/s]  9%|â–‰         | 55/591 [00:03<00:24, 21.59it/s] 10%|â–‰         | 58/591 [00:03<00:24, 21.40it/s] 10%|â–ˆ         | 61/591 [00:04<00:24, 21.29it/s] 11%|â–ˆ         | 64/591 [00:04<00:25, 20.80it/s] 11%|â–ˆâ–        | 67/591 [00:04<00:24, 20.97it/s] 12%|â–ˆâ–        | 70/591 [00:04<00:24, 21.20it/s] 12%|â–ˆâ–        | 73/591 [00:04<00:24, 21.25it/s] 13%|â–ˆâ–Ž        | 76/591 [00:04<00:24, 21.32it/s] 13%|â–ˆâ–Ž        | 79/591 [00:04<00:24, 21.17it/s] 14%|â–ˆâ–        | 82/591 [00:05<00:23, 21.30it/s] 14%|â–ˆâ–        | 85/591 [00:05<00:23, 21.36it/s] 15%|â–ˆâ–        | 88/591 [00:05<00:23, 21.48it/s] 15%|â–ˆâ–Œ        | 91/591 [00:05<00:23, 21.56it/s] 16%|â–ˆâ–Œ        | 94/591 [00:05<00:22, 21.62it/s] 16%|â–ˆâ–‹        | 97/591 [00:05<00:22, 21.56it/s] 17%|â–ˆâ–‹        | 100/591 [00:05<00:22, 21.66it/s] 17%|â–ˆâ–‹        | 103/591 [00:06<00:22, 21.70it/s] 18%|â–ˆâ–Š        | 106/591 [00:06<00:22, 21.76it/s] 18%|â–ˆâ–Š        | 109/591 [00:06<00:22, 21.83it/s] 19%|â–ˆâ–‰        | 112/591 [00:06<00:21, 21.79it/s] 19%|â–ˆâ–‰        | 115/591 [00:06<00:21, 21.69it/s] 20%|â–ˆâ–‰        | 118/591 [00:06<00:21, 21.69it/s] 20%|â–ˆâ–ˆ        | 121/591 [00:06<00:21, 21.79it/s] 21%|â–ˆâ–ˆ        | 124/591 [00:07<00:21, 21.66it/s] 21%|â–ˆâ–ˆâ–       | 127/591 [00:07<00:21, 21.70it/s] 22%|â–ˆâ–ˆâ–       | 130/591 [00:07<00:21, 21.77it/s] 23%|â–ˆâ–ˆâ–Ž       | 133/591 [00:07<00:21, 21.58it/s] 23%|â–ˆâ–ˆâ–Ž       | 136/591 [00:07<00:21, 21.65it/s] 24%|â–ˆâ–ˆâ–Ž       | 139/591 [00:07<00:21, 21.51it/s] 24%|â–ˆâ–ˆâ–       | 142/591 [00:07<00:20, 21.46it/s] 25%|â–ˆâ–ˆâ–       | 145/591 [00:08<00:20, 21.58it/s] 25%|â–ˆâ–ˆâ–Œ       | 148/591 [00:08<00:20, 21.54it/s] 26%|â–ˆâ–ˆâ–Œ       | 151/591 [00:08<00:20, 21.55it/s] 26%|â–ˆâ–ˆâ–Œ       | 154/591 [00:08<00:20, 21.66it/s] 27%|â–ˆâ–ˆâ–‹       | 157/591 [00:08<00:20, 21.68it/s] 27%|â–ˆâ–ˆâ–‹       | 160/591 [00:08<00:19, 21.75it/s] 28%|â–ˆâ–ˆâ–Š       | 163/591 [00:08<00:20, 21.31it/s] 28%|â–ˆâ–ˆâ–Š       | 166/591 [00:08<00:19, 21.28it/s] 29%|â–ˆâ–ˆâ–Š       | 169/591 [00:09<00:19, 21.47it/s] 29%|â–ˆâ–ˆâ–‰       | 172/591 [00:09<00:19, 21.62it/s] 30%|â–ˆâ–ˆâ–‰       | 175/591 [00:09<00:19, 21.82it/s] 30%|â–ˆâ–ˆâ–ˆ       | 178/591 [00:09<00:18, 21.90it/s] 31%|â–ˆâ–ˆâ–ˆ       | 181/591 [00:09<00:18, 21.69it/s] 31%|â–ˆâ–ˆâ–ˆ       | 184/591 [00:09<00:18, 21.64it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 187/591 [00:09<00:19, 21.13it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 190/591 [00:10<00:20, 19.98it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 193/591 [00:10<00:19, 19.93it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 196/591 [00:10<00:19, 20.11it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 199/591 [00:10<00:19, 20.29it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 202/591 [00:10<00:19, 19.78it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 205/591 [00:10<00:19, 19.89it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 208/591 [00:11<00:18, 20.17it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 211/591 [00:11<00:18, 20.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 214/591 [00:11<00:18, 20.50it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 217/591 [00:11<00:18, 20.78it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 220/591 [00:11<00:17, 21.03it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 223/591 [00:11<00:17, 21.08it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 226/591 [00:11<00:17, 21.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 229/591 [00:12<00:17, 21.27it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 232/591 [00:12<00:16, 21.28it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 235/591 [00:12<00:17, 20.87it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 238/591 [00:12<00:17, 20.64it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 241/591 [00:12<00:17, 20.40it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 244/591 [00:12<00:16, 20.43it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 247/591 [00:12<00:17, 19.42it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 250/591 [00:13<00:17, 19.76it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 252/591 [00:13<00:18, 18.75it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 255/591 [00:13<00:17, 19.45it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 258/591 [00:13<00:16, 19.93it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 260/591 [00:13<00:16, 19.87it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 262/591 [00:13<00:16, 19.53it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 265/591 [00:13<00:16, 20.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 267/591 [00:13<00:16, 19.75it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 270/591 [00:14<00:16, 20.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 273/591 [00:14<00:15, 20.20it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 276/591 [00:14<00:15, 20.42it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 279/591 [00:14<00:15, 20.49it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 282/591 [00:14<00:14, 20.87it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 285/591 [00:14<00:14, 21.14it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 288/591 [00:14<00:14, 21.25it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 291/591 [00:15<00:14, 20.92it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 294/591 [00:15<00:14, 21.17it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 297/591 [00:15<00:13, 21.21it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 300/591 [00:15<00:13, 21.09it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 303/591 [00:15<00:13, 21.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 306/591 [00:15<00:13, 21.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 309/591 [00:15<00:13, 21.30it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 312/591 [00:16<00:13, 21.36it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 315/591 [00:16<00:12, 21.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 318/591 [00:16<00:12, 21.42it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 321/591 [00:16<00:12, 21.51it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 324/591 [00:16<00:12, 21.43it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 327/591 [00:16<00:12, 21.46it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 330/591 [00:16<00:12, 21.15it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 333/591 [00:17<00:12, 21.31it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 336/591 [00:17<00:11, 21.37it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 339/591 [00:17<00:11, 21.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 342/591 [00:17<00:11, 21.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 345/591 [00:17<00:11, 21.10it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 348/591 [00:17<00:11, 21.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 351/591 [00:17<00:11, 21.10it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 354/591 [00:18<00:11, 21.30it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 357/591 [00:18<00:11, 21.23it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 360/591 [00:18<00:10, 21.32it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 363/591 [00:18<00:10, 21.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 366/591 [00:18<00:10, 21.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 369/591 [00:18<00:10, 20.48it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 372/591 [00:18<00:10, 20.73it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 375/591 [00:19<00:10, 20.87it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 378/591 [00:19<00:10, 21.11it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 381/591 [00:19<00:09, 21.11it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 384/591 [00:19<00:09, 21.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 387/591 [00:19<00:09, 20.67it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 390/591 [00:19<00:09, 20.53it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 393/591 [00:19<00:09, 20.44it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 396/591 [00:20<00:09, 20.57it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 399/591 [00:20<00:09, 20.66it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 402/591 [00:20<00:09, 20.83it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 405/591 [00:20<00:08, 20.92it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 408/591 [00:20<00:08, 20.70it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 411/591 [00:20<00:08, 21.09it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 414/591 [00:20<00:08, 21.43it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 417/591 [00:21<00:08, 21.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 420/591 [00:21<00:08, 21.22it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 423/591 [00:21<00:07, 21.43it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 426/591 [00:21<00:07, 21.46it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 429/591 [00:21<00:07, 21.44it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 432/591 [00:21<00:07, 21.25it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 435/591 [00:21<00:07, 21.24it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 438/591 [00:22<00:07, 20.95it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 441/591 [00:22<00:07, 21.13it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 444/591 [00:22<00:06, 21.25it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 447/591 [00:22<00:06, 21.33it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 450/591 [00:22<00:06, 21.52it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 453/591 [00:22<00:06, 21.60it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 456/591 [00:22<00:06, 21.72it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 459/591 [00:23<00:06, 21.81it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 462/591 [00:23<00:06, 21.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 465/591 [00:23<00:05, 21.53it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 468/591 [00:23<00:05, 21.80it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 471/591 [00:23<00:05, 21.64it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 474/591 [00:23<00:05, 21.56it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 477/591 [00:23<00:05, 21.57it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 480/591 [00:23<00:05, 21.59it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 483/591 [00:24<00:05, 21.50it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 486/591 [00:24<00:04, 21.56it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 489/591 [00:24<00:04, 21.42it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 492/591 [00:24<00:04, 21.42it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 495/591 [00:24<00:04, 21.26it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 498/591 [00:24<00:04, 21.48it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 501/591 [00:24<00:04, 21.55it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 504/591 [00:25<00:04, 21.65it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 507/591 [00:25<00:03, 21.59it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 510/591 [00:25<00:03, 21.53it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 513/591 [00:25<00:03, 21.41it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 516/591 [00:25<00:03, 21.59it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 519/591 [00:25<00:03, 21.70it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 522/591 [00:25<00:03, 21.24it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 525/591 [00:26<00:03, 20.83it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 528/591 [00:26<00:03, 20.81it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 531/591 [00:26<00:02, 20.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 534/591 [00:26<00:02, 20.83it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 537/591 [00:26<00:02, 21.13it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 540/591 [00:26<00:02, 21.26it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 543/591 [00:26<00:02, 21.19it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 546/591 [00:27<00:02, 21.37it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 549/591 [00:27<00:01, 21.39it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 552/591 [00:27<00:01, 21.40it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 555/591 [00:27<00:01, 21.45it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 558/591 [00:27<00:01, 21.14it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 561/591 [00:28<00:03,  9.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 564/591 [00:28<00:02, 11.93it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 567/591 [00:28<00:01, 13.81it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 570/591 [00:28<00:01, 15.56it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 573/591 [00:28<00:01, 17.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 576/591 [00:29<00:00, 18.35it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 579/591 [00:29<00:00, 19.42it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 582/591 [00:29<00:00, 20.19it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 585/591 [00:29<00:00, 20.80it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 588/591 [00:29<00:00, 21.28it/s]2025-05-09 00:37:47,674 P659171 INFO Train loss: 49.648427
2025-05-09 00:37:47,674 P659171 INFO Evaluation @epoch 2 - batch 591: 

  0%|          | 0/74 [00:00<?, ?it/s][A
  1%|â–         | 1/74 [00:00<00:52,  1.39it/s][A
  8%|â–Š         | 6/74 [00:00<00:07,  9.25it/s][A
 16%|â–ˆâ–Œ        | 12/74 [00:00<00:03, 18.62it/s][A
 24%|â–ˆâ–ˆâ–       | 18/74 [00:01<00:02, 26.73it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 24/74 [00:01<00:01, 33.59it/s][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/74 [00:01<00:01, 40.80it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/74 [00:01<00:00, 44.58it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43/74 [00:01<00:00, 47.90it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50/74 [00:01<00:00, 53.31it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57/74 [00:01<00:00, 56.75it/s][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64/74 [00:01<00:00, 59.43it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71/74 [00:01<00:00, 61.87it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 35.95it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:37:50,259 P659171 INFO [Metrics] AUC: 0.500000 - logloss: 8.002364
2025-05-09 00:37:50,259 P659171 INFO Monitor(max)=0.500000 STOP!
2025-05-09 00:37:50,259 P659171 INFO Reduce learning rate on plateau: 0.000100

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 591/591 [00:32<00:00,  3.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 591/591 [00:32<00:00, 18.27it/s]2025-05-09 00:37:50,364 P659171 INFO ************ Epoch=2 end ************

  0%|          | 0/591 [00:00<?, ?it/s]  0%|          | 1/591 [00:01<12:45,  1.30s/it]  1%|          | 4/591 [00:01<02:47,  3.51it/s]  1%|          | 7/591 [00:01<01:32,  6.34it/s]  2%|â–         | 10/591 [00:01<01:03,  9.16it/s]  2%|â–         | 13/591 [00:01<00:49, 11.65it/s]  3%|â–Ž         | 16/591 [00:02<00:41, 13.96it/s]  3%|â–Ž         | 19/591 [00:02<00:36, 15.84it/s]  4%|â–Ž         | 22/591 [00:02<00:32, 17.26it/s]  4%|â–         | 25/591 [00:02<00:30, 18.34it/s]  5%|â–         | 28/591 [00:02<00:29, 19.06it/s]  5%|â–Œ         | 31/591 [00:02<00:28, 19.63it/s]  6%|â–Œ         | 34/591 [00:02<00:28, 19.73it/s]  6%|â–‹         | 37/591 [00:03<00:27, 20.23it/s]  7%|â–‹         | 40/591 [00:03<00:26, 20.53it/s]  7%|â–‹         | 43/591 [00:03<00:26, 20.83it/s]  8%|â–Š         | 46/591 [00:03<00:25, 21.02it/s]  8%|â–Š         | 49/591 [00:03<00:25, 21.18it/s]  9%|â–‰         | 52/591 [00:03<00:25, 21.20it/s]  9%|â–‰         | 55/591 [00:03<00:25, 21.29it/s] 10%|â–‰         | 58/591 [00:03<00:24, 21.43it/s] 10%|â–ˆ         | 61/591 [00:04<00:24, 21.58it/s] 11%|â–ˆ         | 64/591 [00:04<00:24, 21.54it/s] 11%|â–ˆâ–        | 67/591 [00:04<00:24, 21.49it/s] 12%|â–ˆâ–        | 70/591 [00:04<00:24, 21.31it/s] 12%|â–ˆâ–        | 73/591 [00:04<00:24, 21.32it/s] 13%|â–ˆâ–Ž        | 76/591 [00:04<00:24, 21.28it/s] 13%|â–ˆâ–Ž        | 79/591 [00:04<00:24, 21.28it/s] 14%|â–ˆâ–        | 82/591 [00:05<00:23, 21.22it/s] 14%|â–ˆâ–        | 85/591 [00:05<00:23, 21.28it/s] 15%|â–ˆâ–        | 88/591 [00:05<00:23, 21.22it/s] 15%|â–ˆâ–Œ        | 91/591 [00:05<00:23, 21.21it/s] 16%|â–ˆâ–Œ        | 94/591 [00:05<00:23, 21.11it/s] 16%|â–ˆâ–‹        | 97/591 [00:05<00:23, 21.19it/s] 17%|â–ˆâ–‹        | 100/591 [00:05<00:23, 21.26it/s] 17%|â–ˆâ–‹        | 103/591 [00:06<00:23, 21.14it/s] 18%|â–ˆâ–Š        | 106/591 [00:06<00:22, 21.30it/s] 18%|â–ˆâ–Š        | 109/591 [00:06<00:22, 21.38it/s] 19%|â–ˆâ–‰        | 112/591 [00:06<00:22, 21.05it/s] 19%|â–ˆâ–‰        | 115/591 [00:06<00:23, 20.56it/s] 20%|â–ˆâ–‰        | 118/591 [00:06<00:22, 20.85it/s] 20%|â–ˆâ–ˆ        | 121/591 [00:06<00:22, 21.05it/s] 21%|â–ˆâ–ˆ        | 124/591 [00:07<00:22, 21.19it/s] 21%|â–ˆâ–ˆâ–       | 127/591 [00:07<00:22, 20.99it/s] 22%|â–ˆâ–ˆâ–       | 130/591 [00:07<00:22, 20.94it/s] 23%|â–ˆâ–ˆâ–Ž       | 133/591 [00:07<00:21, 21.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 136/591 [00:07<00:21, 20.98it/s] 24%|â–ˆâ–ˆâ–Ž       | 139/591 [00:07<00:21, 21.16it/s] 24%|â–ˆâ–ˆâ–       | 142/591 [00:07<00:21, 21.27it/s] 25%|â–ˆâ–ˆâ–       | 145/591 [00:08<00:20, 21.35it/s] 25%|â–ˆâ–ˆâ–Œ       | 148/591 [00:08<00:20, 21.21it/s] 26%|â–ˆâ–ˆâ–Œ       | 151/591 [00:08<00:20, 21.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 154/591 [00:08<00:20, 20.95it/s] 27%|â–ˆâ–ˆâ–‹       | 157/591 [00:08<00:20, 21.01it/s] 27%|â–ˆâ–ˆâ–‹       | 160/591 [00:08<00:20, 21.31it/s] 28%|â–ˆâ–ˆâ–Š       | 163/591 [00:08<00:19, 21.42it/s] 28%|â–ˆâ–ˆâ–Š       | 166/591 [00:09<00:20, 21.07it/s] 29%|â–ˆâ–ˆâ–Š       | 169/591 [00:09<00:20, 21.06it/s] 29%|â–ˆâ–ˆâ–‰       | 172/591 [00:09<00:20, 20.81it/s] 30%|â–ˆâ–ˆâ–‰       | 175/591 [00:09<00:20, 20.41it/s] 30%|â–ˆâ–ˆâ–ˆ       | 178/591 [00:09<00:20, 20.51it/s] 31%|â–ˆâ–ˆâ–ˆ       | 181/591 [00:09<00:19, 20.80it/s] 31%|â–ˆâ–ˆâ–ˆ       | 184/591 [00:09<00:19, 20.78it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 187/591 [00:10<00:19, 20.49it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 190/591 [00:10<00:19, 20.67it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 193/591 [00:10<00:19, 20.66it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 196/591 [00:10<00:19, 20.74it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 199/591 [00:10<00:19, 20.41it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 202/591 [00:10<00:19, 20.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 205/591 [00:10<00:18, 20.65it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 208/591 [00:11<00:18, 20.78it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 211/591 [00:11<00:18, 21.04it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 214/591 [00:11<00:17, 20.95it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 217/591 [00:11<00:17, 20.96it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 220/591 [00:11<00:17, 20.86it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 223/591 [00:11<00:17, 21.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 226/591 [00:11<00:17, 21.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 229/591 [00:12<00:17, 21.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 232/591 [00:12<00:17, 21.04it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 235/591 [00:12<00:16, 21.03it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 238/591 [00:12<00:16, 20.97it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 241/591 [00:12<00:16, 21.01it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 244/591 [00:12<00:16, 21.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 247/591 [00:12<00:16, 21.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 250/591 [00:13<00:15, 21.47it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 253/591 [00:13<00:15, 21.57it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 256/591 [00:13<00:15, 21.37it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 259/591 [00:13<00:15, 21.47it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 262/591 [00:13<00:15, 21.52it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 265/591 [00:13<00:15, 21.53it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 268/591 [00:13<00:15, 21.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 271/591 [00:14<00:15, 21.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 274/591 [00:14<00:15, 21.11it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 277/591 [00:14<00:14, 21.12it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 280/591 [00:14<00:14, 21.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 283/591 [00:14<00:14, 21.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 286/591 [00:14<00:14, 21.15it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 289/591 [00:14<00:14, 21.20it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 292/591 [00:15<00:14, 21.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 295/591 [00:15<00:14, 20.76it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 298/591 [00:15<00:14, 20.84it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 301/591 [00:15<00:13, 20.84it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 304/591 [00:15<00:13, 20.81it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 307/591 [00:15<00:13, 20.78it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 310/591 [00:15<00:13, 20.91it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 313/591 [00:16<00:13, 20.60it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 316/591 [00:16<00:13, 20.60it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 319/591 [00:16<00:13, 20.70it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 322/591 [00:16<00:12, 20.87it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 325/591 [00:16<00:12, 21.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 328/591 [00:16<00:12, 21.18it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 331/591 [00:16<00:12, 21.40it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 334/591 [00:17<00:12, 21.37it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 337/591 [00:17<00:11, 21.38it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 340/591 [00:17<00:11, 21.48it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 343/591 [00:17<00:11, 21.35it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 346/591 [00:17<00:11, 21.41it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 349/591 [00:17<00:11, 21.54it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 352/591 [00:17<00:11, 21.56it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 355/591 [00:18<00:10, 21.51it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 358/591 [00:18<00:10, 21.42it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 361/591 [00:18<00:10, 21.40it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 364/591 [00:18<00:10, 21.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 367/591 [00:18<00:10, 21.34it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 370/591 [00:18<00:10, 21.27it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 373/591 [00:18<00:10, 21.41it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 376/591 [00:19<00:10, 21.30it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 379/591 [00:19<00:09, 21.28it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 382/591 [00:19<00:09, 21.29it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 385/591 [00:19<00:09, 21.42it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 388/591 [00:19<00:09, 20.83it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 391/591 [00:19<00:09, 20.67it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 394/591 [00:19<00:09, 20.77it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 397/591 [00:20<00:09, 20.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 400/591 [00:20<00:09, 20.83it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 403/591 [00:20<00:08, 21.10it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 406/591 [00:20<00:08, 21.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 409/591 [00:20<00:08, 21.60it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 412/591 [00:20<00:08, 21.56it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 415/591 [00:20<00:08, 21.62it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 418/591 [00:21<00:08, 21.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 421/591 [00:21<00:08, 20.93it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 424/591 [00:21<00:07, 21.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 427/591 [00:21<00:07, 20.88it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 430/591 [00:21<00:07, 21.20it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 433/591 [00:21<00:07, 20.78it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 436/591 [00:21<00:07, 20.86it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 439/591 [00:22<00:07, 20.94it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 442/591 [00:22<00:07, 21.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 445/591 [00:22<00:06, 21.14it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 448/591 [00:22<00:06, 21.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 451/591 [00:22<00:07, 19.56it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 453/591 [00:22<00:07, 19.31it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 456/591 [00:22<00:06, 19.29it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 459/591 [00:23<00:06, 19.28it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 461/591 [00:23<00:06, 19.24it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 463/591 [00:23<00:06, 18.84it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 466/591 [00:23<00:06, 19.73it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 469/591 [00:23<00:06, 20.32it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 472/591 [00:23<00:05, 20.60it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 475/591 [00:23<00:05, 20.57it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 478/591 [00:23<00:05, 20.82it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 481/591 [00:24<00:05, 20.21it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 484/591 [00:24<00:05, 20.65it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 487/591 [00:24<00:05, 20.79it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 490/591 [00:24<00:04, 20.80it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 493/591 [00:24<00:04, 20.91it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 496/591 [00:24<00:04, 20.94it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 499/591 [00:25<00:04, 20.87it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 502/591 [00:25<00:04, 20.88it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 505/591 [00:25<00:04, 20.58it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 508/591 [00:25<00:04, 20.35it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 511/591 [00:25<00:03, 20.50it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 514/591 [00:25<00:03, 19.36it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 516/591 [00:25<00:03, 19.12it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 519/591 [00:26<00:03, 19.53it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 521/591 [00:26<00:03, 18.84it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 523/591 [00:26<00:03, 18.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 525/591 [00:26<00:03, 17.89it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 527/591 [00:26<00:03, 17.83it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 530/591 [00:26<00:03, 18.86it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 533/591 [00:26<00:02, 19.48it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 536/591 [00:26<00:02, 19.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 539/591 [00:27<00:02, 19.35it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 542/591 [00:27<00:02, 19.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 545/591 [00:27<00:02, 20.19it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 548/591 [00:27<00:02, 20.53it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 551/591 [00:27<00:01, 20.80it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 554/591 [00:27<00:01, 20.93it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 557/591 [00:27<00:01, 20.67it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 560/591 [00:28<00:02, 10.61it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 563/591 [00:28<00:02, 12.60it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 566/591 [00:28<00:01, 14.49it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 569/591 [00:28<00:01, 16.24it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 572/591 [00:29<00:01, 17.68it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 575/591 [00:29<00:00, 18.81it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 578/591 [00:29<00:00, 19.75it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 581/591 [00:29<00:00, 20.47it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 584/591 [00:29<00:00, 21.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 587/591 [00:29<00:00, 21.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 590/591 [00:29<00:00, 21.42it/s]2025-05-09 00:38:20,282 P659171 INFO Train loss: 49.648775
2025-05-09 00:38:20,283 P659171 INFO Evaluation @epoch 3 - batch 591: 

  0%|          | 0/74 [00:00<?, ?it/s][A
  1%|â–         | 1/74 [00:00<00:47,  1.54it/s][A
  5%|â–Œ         | 4/74 [00:00<00:10,  6.62it/s][A
 15%|â–ˆâ–        | 11/74 [00:00<00:03, 18.92it/s][A
 22%|â–ˆâ–ˆâ–       | 16/74 [00:00<00:02, 24.60it/s][A
 28%|â–ˆâ–ˆâ–Š       | 21/74 [00:01<00:01, 30.22it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/74 [00:01<00:01, 38.67it/s][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35/74 [00:01<00:00, 45.02it/s][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/74 [00:01<00:00, 47.80it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47/74 [00:01<00:00, 50.82it/s][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54/74 [00:01<00:00, 53.99it/s][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/74 [00:01<00:00, 56.66it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/74 [00:01<00:00, 58.22it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 36.36it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:38:22,842 P659171 INFO [Metrics] AUC: 0.500000 - logloss: 8.002364
2025-05-09 00:38:22,843 P659171 INFO Monitor(max)=0.500000 STOP!
2025-05-09 00:38:22,843 P659171 INFO Reduce learning rate on plateau: 0.000010
2025-05-09 00:38:22,843 P659171 INFO ********* Epoch=3 early stop *********

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 590/591 [00:32<00:00, 18.11it/s]2025-05-09 00:38:22,939 P659171 INFO Training finished.
2025-05-09 00:38:22,939 P659171 INFO Load best model: /home/dxlab/jupyter/jinhee/scv/checkpoints/KKBox_x1/EulerNet_KKBox_x1.model
/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/fuxictr/pytorch/models/rank_model.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(checkpoint, map_location="cpu")
2025-05-09 00:38:22,963 P659171 INFO ****** Validation evaluation ******

  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:52,  1.40it/s]  5%|â–Œ         | 4/74 [00:00<00:11,  6.08it/s] 15%|â–ˆâ–        | 11/74 [00:00<00:03, 17.75it/s] 24%|â–ˆâ–ˆâ–       | 18/74 [00:01<00:02, 27.75it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 24/74 [00:01<00:01, 34.61it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/74 [00:01<00:01, 41.54it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/74 [00:01<00:00, 45.64it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43/74 [00:01<00:00, 49.05it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50/74 [00:01<00:00, 53.80it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57/74 [00:01<00:00, 56.68it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64/74 [00:01<00:00, 59.19it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71/74 [00:01<00:00, 60.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 36.19it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:38:25,560 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
2025-05-09 00:38:25,722 P659171 INFO ******** Test evaluation ********
2025-05-09 00:38:25,722 P659171 INFO Loading datasets...
2025-05-09 00:38:28,474 P659171 INFO Test samples: total/737743, blocks/1
2025-05-09 00:38:28,474 P659171 INFO Loading test data done.

  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:45,  1.59it/s]  4%|â–         | 3/74 [00:00<00:14,  4.87it/s] 12%|â–ˆâ–        | 9/74 [00:00<00:04, 15.70it/s] 19%|â–ˆâ–‰        | 14/74 [00:00<00:02, 22.78it/s] 26%|â–ˆâ–ˆâ–Œ       | 19/74 [00:01<00:03, 18.10it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/74 [00:01<00:01, 26.62it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/74 [00:01<00:01, 34.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39/74 [00:01<00:00, 39.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/74 [00:01<00:00, 44.84it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52/74 [00:01<00:00, 48.10it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59/74 [00:01<00:00, 53.25it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67/74 [00:02<00:00, 57.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 60.80it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 32.41it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:38:31,271 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:01<01:14,  1.03s/it]  9%|â–‰         | 7/74 [00:01<00:08,  8.11it/s] 18%|â–ˆâ–Š        | 13/74 [00:01<00:03, 15.61it/s] 26%|â–ˆâ–ˆâ–Œ       | 19/74 [00:01<00:02, 23.05it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 25/74 [00:01<00:01, 29.67it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32/74 [00:01<00:01, 37.41it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38/74 [00:01<00:00, 42.39it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44/74 [00:01<00:00, 45.88it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51/74 [00:01<00:00, 50.15it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58/74 [00:02<00:00, 53.81it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65/74 [00:02<00:00, 57.35it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72/74 [00:02<00:00, 59.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 31.73it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:38:34,175 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.0 OrderedDict([('logloss', 8.00236363894399), ('AUC', 0.5)]) tensor(129., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:52,  1.38it/s]  3%|â–Ž         | 2/74 [00:01<00:34,  2.10it/s]  5%|â–Œ         | 4/74 [00:01<00:14,  4.79it/s] 15%|â–ˆâ–        | 11/74 [00:01<00:03, 15.87it/s] 24%|â–ˆâ–ˆâ–       | 18/74 [00:01<00:02, 25.83it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 25/74 [00:01<00:01, 34.28it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32/74 [00:01<00:01, 40.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38/74 [00:01<00:00, 45.23it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44/74 [00:01<00:00, 48.75it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51/74 [00:01<00:00, 53.67it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58/74 [00:01<00:00, 57.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65/74 [00:02<00:00, 60.82it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72/74 [00:02<00:00, 63.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 31.81it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:38:37,146 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.1 OrderedDict([('logloss', 8.00236363894399), ('AUC', 0.5)]) tensor(117., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:47,  1.54it/s]  5%|â–Œ         | 4/74 [00:00<00:10,  6.60it/s] 12%|â–ˆâ–        | 9/74 [00:00<00:04, 15.16it/s] 18%|â–ˆâ–Š        | 13/74 [00:01<00:04, 14.72it/s] 26%|â–ˆâ–ˆâ–Œ       | 19/74 [00:01<00:02, 22.86it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 25/74 [00:01<00:01, 30.46it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/74 [00:01<00:01, 32.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/74 [00:01<00:00, 39.27it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42/74 [00:01<00:00, 43.79it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/74 [00:01<00:00, 47.42it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56/74 [00:01<00:00, 54.22it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 63/74 [00:02<00:00, 58.11it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70/74 [00:02<00:00, 60.27it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 32.81it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:38:39,948 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.2 OrderedDict([('logloss', 8.00236363894399), ('AUC', 0.5)]) tensor(104., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:45,  1.59it/s]  5%|â–Œ         | 4/74 [00:00<00:13,  5.12it/s] 14%|â–ˆâ–Ž        | 10/74 [00:01<00:04, 13.96it/s] 19%|â–ˆâ–‰        | 14/74 [00:01<00:03, 18.57it/s] 26%|â–ˆâ–ˆâ–Œ       | 19/74 [00:01<00:02, 24.39it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 25/74 [00:01<00:01, 31.69it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/74 [00:01<00:01, 38.25it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/74 [00:01<00:01, 29.94it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43/74 [00:01<00:00, 35.58it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51/74 [00:01<00:00, 43.94it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57/74 [00:02<00:00, 47.67it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64/74 [00:02<00:00, 51.64it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71/74 [00:02<00:00, 55.84it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 30.67it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:38:42,913 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.30000000000000004 OrderedDict([('logloss', 8.00236363894399), ('AUC', 0.5)]) tensor(91., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:54,  1.33it/s]  3%|â–Ž         | 2/74 [00:00<00:26,  2.67it/s] 11%|â–ˆ         | 8/74 [00:00<00:05, 12.83it/s] 16%|â–ˆâ–Œ        | 12/74 [00:01<00:04, 13.76it/s] 26%|â–ˆâ–ˆâ–Œ       | 19/74 [00:01<00:03, 16.69it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 25/74 [00:01<00:02, 23.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/74 [00:01<00:01, 29.52it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/74 [00:01<00:01, 30.59it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42/74 [00:02<00:00, 36.31it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49/74 [00:02<00:00, 43.21it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56/74 [00:02<00:00, 48.17it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64/74 [00:02<00:00, 54.78it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71/74 [00:02<00:00, 58.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 28.06it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:38:46,126 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.4 OrderedDict([('logloss', 8.00236363894399), ('AUC', 0.5)]) tensor(78., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:46,  1.56it/s]  5%|â–Œ         | 4/74 [00:00<00:14,  4.94it/s] 15%|â–ˆâ–        | 11/74 [00:01<00:04, 15.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 17/74 [00:01<00:02, 23.07it/s] 30%|â–ˆâ–ˆâ–‰       | 22/74 [00:01<00:02, 19.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 29/74 [00:01<00:01, 27.12it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/74 [00:01<00:01, 33.58it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42/74 [00:01<00:00, 38.53it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49/74 [00:01<00:00, 44.71it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56/74 [00:02<00:00, 50.60it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 63/74 [00:02<00:00, 54.90it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70/74 [00:02<00:00, 58.62it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 30.83it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:38:49,020 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.5 OrderedDict([('logloss', 8.00236363894399), ('AUC', 0.5)]) tensor(65., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<01:09,  1.05it/s]  4%|â–         | 3/74 [00:01<00:20,  3.50it/s] 12%|â–ˆâ–        | 9/74 [00:01<00:05, 12.12it/s] 22%|â–ˆâ–ˆâ–       | 16/74 [00:01<00:02, 22.14it/s] 28%|â–ˆâ–ˆâ–Š       | 21/74 [00:01<00:01, 27.46it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/74 [00:01<00:01, 35.96it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34/74 [00:01<00:00, 41.14it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/74 [00:01<00:00, 46.64it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/74 [00:01<00:00, 51.61it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/74 [00:01<00:00, 55.79it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/74 [00:02<00:00, 58.86it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69/74 [00:02<00:00, 61.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 32.08it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:38:51,845 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.6000000000000001 OrderedDict([('logloss', 8.00236363894399), ('AUC', 0.5)]) tensor(52., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:47,  1.54it/s]  3%|â–Ž         | 2/74 [00:01<00:39,  1.84it/s] 12%|â–ˆâ–        | 9/74 [00:01<00:06, 10.78it/s] 20%|â–ˆâ–ˆ        | 15/74 [00:01<00:03, 18.21it/s] 28%|â–ˆâ–ˆâ–Š       | 21/74 [00:01<00:02, 25.26it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/74 [00:01<00:01, 33.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34/74 [00:01<00:01, 39.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40/74 [00:01<00:00, 43.72it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47/74 [00:01<00:00, 49.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54/74 [00:01<00:00, 53.69it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/74 [00:02<00:00, 56.22it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/74 [00:02<00:00, 58.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 30.80it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:38:54,786 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.7000000000000001 OrderedDict([('logloss', 8.00236363894399), ('AUC', 0.5)]) tensor(39., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:42,  1.73it/s]  3%|â–Ž         | 2/74 [00:01<00:35,  2.01it/s] 11%|â–ˆ         | 8/74 [00:01<00:06, 10.29it/s] 19%|â–ˆâ–‰        | 14/74 [00:01<00:03, 18.69it/s] 27%|â–ˆâ–ˆâ–‹       | 20/74 [00:01<00:02, 25.52it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 27/74 [00:01<00:01, 33.90it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34/74 [00:01<00:00, 41.19it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40/74 [00:01<00:00, 45.19it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47/74 [00:01<00:00, 50.63it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54/74 [00:01<00:00, 54.72it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/74 [00:02<00:00, 54.52it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67/74 [00:02<00:00, 55.59it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 57.88it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 31.59it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:38:57,727 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.8 OrderedDict([('logloss', 8.00236363894399), ('AUC', 0.5)]) tensor(26., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:50,  1.44it/s]  7%|â–‹         | 5/74 [00:00<00:08,  7.89it/s] 15%|â–ˆâ–        | 11/74 [00:01<00:04, 13.18it/s] 19%|â–ˆâ–‰        | 14/74 [00:01<00:03, 16.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 17/74 [00:01<00:04, 13.25it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 24/74 [00:01<00:02, 22.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/74 [00:01<00:01, 30.25it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/74 [00:01<00:01, 35.69it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43/74 [00:01<00:00, 40.81it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50/74 [00:02<00:00, 47.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57/74 [00:02<00:00, 52.64it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64/74 [00:02<00:00, 55.35it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71/74 [00:02<00:00, 57.73it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 29.19it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:39:00,936 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
/home/dxlab/jupyter/jinhee/scv/run_expid.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  inter_orders = torch.load(f"./{experiment_id}_weight.pt")

0.9 OrderedDict([('logloss', 8.00236363894399), ('AUC', 0.5)]) tensor(13., device='cuda:1')
  0%|          | 0/74 [00:00<?, ?it/s]  1%|â–         | 1/74 [00:00<00:53,  1.36it/s]  7%|â–‹         | 5/74 [00:00<00:09,  7.54it/s] 15%|â–ˆâ–        | 11/74 [00:00<00:03, 17.26it/s] 20%|â–ˆâ–ˆ        | 15/74 [00:01<00:04, 13.18it/s] 28%|â–ˆâ–ˆâ–Š       | 21/74 [00:01<00:02, 20.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 27/74 [00:01<00:01, 27.15it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32/74 [00:01<00:01, 26.63it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/74 [00:01<00:01, 28.41it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42/74 [00:01<00:00, 34.72it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49/74 [00:02<00:00, 42.31it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56/74 [00:02<00:00, 47.64it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64/74 [00:02<00:00, 54.12it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71/74 [00:02<00:00, 57.75it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00, 28.95it/s]/home/dxlab/jupyter/jinhee/scv/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2845: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.
  warnings.warn(
2025-05-09 00:39:04,058 P659171 INFO [Metrics] logloss: 8.002364 - AUC: 0.500000
2025-05-09 00:39:04,063 P659171 INFO ******** Remove Model Weights ********

1.0 OrderedDict([('logloss', 8.00236363894399), ('AUC', 0.5)]) tensor(0., device='cuda:1')
